Digital Thailand - AI Ethics Guideline 

1 | P a g e  

 
 
Digital Thailand - AI Ethics Guideline 

ค ำน ำ (Introduction) 

เราคงปฏิเสธไม่ได้ว่าปัจจุบันนี

้เทคโนโลยีปัญญาประดิษฐ์ได้เข้ามามีบทบาทในกิจกรรม 

ด้านต่าง ๆ ของมนุษย์เพิ

่มมากขึ

้น สิ

่งต่าง ๆ ที

่เราใช้งานกันในชีวิตประจ าวัน อาทิ เทคโนโลยีผู

้ช่วย

อัจฉริยะบนสมาร์ทโฟน อย่าง Siri, Alexa และ Google Assistant เทคโนโลยีกึ

่งอัตโนมัติ 

ในรถยนต์ Tesla หรือเป็น Social Media Feed บน Facebook และ Snapchat บริการเพลง

หรือภาพยนต์บน YouTube และ Netflix ล้วนมีเทคโนโลยีปัญญาประดิษฐ์ท างานอยู

่เบื

้องหลัง  

เพื

่อคอยส่งข้อมูลและแจ้งเตือนผู

้ใช้งาน โดยอาศัยข้อมูลพฤติกรรมการใช้งานของผู

้ใช้งาน 

มาปรับการส่งข้อมูลให้เหมาะสมกับความต้องการ ไปจนถึงเทคโนโลยีการน าทางที

่เราใช้กันเกือบ

ทุกวันอย่าง Google Maps ก็ใช้เทคโนโลยีปัญญาประดิษฐ์ ในการประมวลผลข้อมูลจราจรแบบ

เรียลไทม์เพื

่อหาเส้นทางที

่ดีที

่สุดในการไปถึงจุดหมายปลายทาง เป็นต้น 

นอกเหนือจากนี

้ในองค์กรที

่ให้ความส าคัญด้านข้อมูลและเทคโนโลยีสารสนเทศในประเทศไทย 

อาทิ ธนาคาร บริษัทหลักทรัพย์ ประกันภัย สายการบิน กองทัพ ยังมีการใช้งานเครื

่องมือในการ

รักษาความมั

่นคงปลอดภัยของข้อมูล เพื

่อป้องกันและตรวจจับภัยคุกคามทางไซเบอร์ รวมถึง

เทคโนโลยีในการตรวจสอบการฉ้อโกงหรือพฤติกรรมไม่พึงประสงค์ต่าง ๆ ซึ

่งมีการใช้เทคโนโลยี

ปัญญาประดิษฐ์เป็นส่วนหนึ

่งของเครื

่องมือในการประมวลผลและตัดสินใจในท างาน หรือแม้แต่

เป็นเทคโนโลยีหลักในการตรวจสอบและป้องกันภัยคุกคามในหลายผลิตภัณฑ์ อาทิ Cylance 

Anti-Malware เป็นต้น 

อย่างไรก็ดีเทคโนโลยีปัญญาประดิษฐ์นั

้นมีการพัฒนามากขึ

้นเรื

่อย ๆ จนสามารถเอาชนะ

ความสามารถของมนุษย์ได้ในหลายด้าน อาทิ Alpha Go ซึ
Google DeepMind1 ที

่สามารถเอาชนะแชมป์โลกเกมหมากล้อมได้ในปี 2560 Watson ซึ

่งเป็น

่งเป็นปัญญาประดิษฐ์ที

่สร้างขึ

้นโดย 

1 David Silver at all. Mastering the game of Go with Deep neural networks and tree search. Nature. Jan 2016. ดูได้จาก 
https://storage.googleapis.com/deepmind-media/alphago/AlphaGoNaturePaper.pdf. 

ก | P a g e  

 
 
 
 
                                                           
Digital Thailand - AI Ethics Guideline 

ปัญญาประดิษฐ์ที

่สร้างขึ

้นโดย IBM ซึ

่งสามารถวินิจฉัยโรคได้แม่นย ากว่าแพทย์ที

จนก่อให้เกิดความกังวลว่าเทคโนโลยีปัญญาประดิษฐ์จะมีโอกาสเข้ามาแทนที

่มีความเชี

่ยวชาญ2 
่งานในหลายด้าน 

ของมนุษย์ และท าให้มนุษย์ต้องตกงานในหลายสาขาอาชีพ นอกจากความกังวลดังกล่าวแล้วการ

ออกแบบและพัฒนาปัญญาประดิษฐ์เอง ยังมีโอกาสท าให้ผลลัพธ์เอนเอียงและก่อให้เกิดความไม่

เป็นธรรมขึ

้นได้ ตั

้งแต่การใช้เสียงสตรี ในการพูดโต้ตอบโดยปริยายในเทคโนโลยีผู

้ช่วยอัจฉริยะของ

บริษัทผู

้ผลิตต่าง ๆ3 จนถึงโปรแกรมที

่ส่งผลกระทบต่อชีวิตของมนุษย์ ตัวอย่างเช่น อัลกอริทึม

ปัญญาประดิษฐ์ในโปรแกรม COMPAS ของบริษัท Northpointe ที

่ถูกใช้งานโดยศาลในสหรัฐ  

ซึ

่งได้รับการตรวจสอบพบว่าระบบมีความเอนเอียงไปในทางที

่จะตัดสินว่าจ าเลยผิวด ามีโอกาสจะ

เป็นผู

้กระท าผิดซ้

 ามากกว่าจ าเลยผิวขาว4 เป็นต้น การน าปัญญาประดิษฐ์ไปใช้ในทางที
่ส าคัญมากเช่นเดียวกัน ซึ

่ง DeepLocker โปรแกรมไม่พึง

้งในแง่

่ผิดทั

จริยธรรมและกฎหมายก็เป็นประเด็นที

ประสงค์ที

่อาศัยเทคโนโลยีปัญญาประดิษฐ์ที

ความเข้าใจถึงโปรแกรมไม่พึงประสงค์ในลักษณะนี

่ได้รับการสร้างโดย IBM โดยมีวัตถุประสงค์เพื

่อท า
้ว่าจะสร้างผลกระทบได้อย่างไรบ้าง 5  

เป็นตัวอย่างหนึ

่งที

่ท าให้เราต้องตระหนักถึงความจ าเป็นในการพิจารณาเฝ้าระวังการพัฒนา

ปัญญาประดิษฐ์นับต่อจากนี

้ไป 

เอกสารหลักการและแนวทางจริยธรรมปัญญาประดิษฐ์ฉบับนี
ผู
้ออกแบบ ผู
้วิจัย ผู
้ถึงความเสี
ของตนเอง และให้ผู
ปัญญาประดิษฐ์ หน่วยงานรัฐและหน่วยงานก ากับดูแลปัญญาประดิษฐ์ ทั

่อให้
้ให้บริการปัญญาประดิษฐ์ ใช้เป็นแนวทางส าหรับการด าเนินงาน
่ยงของการใช้บริการ
้งระดับประเทศและ

้พัฒนา และผู
้รับบริการได้ทราบถึงสิทธิและตระหนักรู

้จึงได้รับการสร้างขึ

้นเพื

2 Monegain B. IBM Watson pinpoints rare form of leukemia after doctor misdiagnosed patient. Healthcare IT News. Aug 8  2016. จาก 
https://www.healthcareitnews.com/news/ibm-watson-pinpoints-rare-form-leukemia-after-doctors-misdiagnosed-patient.  
3 UNESCO and EQUALS Skills Coalition. I’d blush if I cloud: Closing gender divides in digital skills through education. 2019. จาก 
https://unesdoc.unesco.org/ark:/48223/pf0000367416. 
4 Julia Angwin., Jeff Larson., Surya Mattu. and Lauren Kirchner. Machine Bias: There’s software used across the country to predict future 
criminals. And it’s biased against blacks. ProPublica. May 23 2016. จาก https://www.propublica.org/article/machine-bias-risk-
assessments-in-criminal-sentencing.  
5 Dhilung Kirat., Juyong Jang., and Marc Ph. Stoecklin. DeepLocker – Concealing Targeted Attacks with AI Locksmithing. Blackhat USA 
2018. Aug 9 2018. จาก https://www.blackhat.com/us-18/briefings/schedule/#deeplocker---concealing-targeted-attacks-with-ai-
locksmithing-11549. 

ข | P a g e  

 
 
                                                           
 
Digital Thailand - AI Ethics Guideline 

่อใช้เป็นแนวทางในการส่งเสริม สนับสนุน รวมถึงก ากับดูแลเทคโนโลยี
ระดับองค์กร เพื
่นคงปลอดภัย ได้รับการพัฒนาและ
่อถือ มั
่อท าให้ปัญญาประดิษฐ์มีความน่าเชื
ปัญญาประดิษฐ์ เพื
ใช้งาน ก่อให้เกิดประโยชน์กับมนุษย์ สังคมและสิ
่งแวดล้อม ด้วยความโปร่งใส ครอบคลุมและเป็น
ธรรม สอดคล้องกับกฎหมาย จริยธรรมและสิทธิมนุษยชน รวมถึงสอดคล้องกับยุทธศาสตร์ชาติ 20 
ปี (2561 – 2580) ยุทธศาสตร์ที
่ได้กล่าวถึงการใช้เทคโนโลยีดิจิทัล ข้อมูลและปัญญาประดิษฐ์
่มศักยภาพและความสามารถในการแข่งขันของอุตสาหกรรมและบริการ6 และยุทธศาสตร์
ในการเพิ
กระทรวงดิจิทัลเพื
่องการพัฒนาโครงสร้าง
่จะพัฒนาและส่งเสริมการลงทุนและการใช้ประโยชน์จาก
้นฐานดิจิทัลของประเทศ ซึ
พื
อินเทอร์เน็ตในทุกสิ

่งมีกลยุทธ์ที
่ง (IOT) และปัญญาประดิษฐ์ (AI)7 

่อเศรษฐกิจและสังคม พ.ศ. 2563 – 2567 ยุทธศาสตร์ที

่ 2 ที

่ 1 เรื

่อง ยุทธศาสตร์ชาติ (พ.ศ. 2561 – 2580). ราชกิจจานุเบกษา. 13 ตุลาคม พ.ศ. 2561 เล่ม 135 ตอนที

6 ประกาศ เรื
http://www.ratchakitcha.soc.go.th/DATA/PDF/2561/A/082/T_0001.PDF.  
7 แผนยุทธศาสตร์กระทรวงดิจิทัลเพื
http://www.mdes.go.th/assets/portals/1/files/%E0%B9%81%E0%B8%9C%E0%B8%99%E0%B8%A2%E0%B8%B8%E0%B8%97%E0%B8%
98%E0%B8%A8%E0%B8%B2%E0%B8%AA%E0%B8%95%E0%B8%A3%E0%B9%8C%20%E0%B8%94%E0%B8%A8.%2063-
67%20final%281%29.pdf. 

่อเศรษฐกิจและสังคม พ.ศ. 2563 – 2567. หน้า 5. จาก 

่ 82 ก. หน้า 25. จาก 

ค | P a g e  

 
                                                           
 
Digital Thailand - AI Ethics Guideline 

สำรบัญ (Table of Content) 

ก 

ค ำน ำ 

          กำรศึกษำและวิเครำะห์  

          (Study and analysis) 

1 

  หลักกำรทำงจริยธรรมปัญญำประดิษฐ์  

8 

  (AI Ethic Principles) 

16

แนวทำงปฏิบัติทำงจริยธรรม

ปัญญำประดิษฐ์ (AI Ethic Guidelines) 

36 

4

อภิธำนศัพท์ (Glossary) 

38 

เอกสำรอ้ำงอิง 

4 

ค | P a g e  

 
 
 
 
 
 
 
 
 
 
Digital Thailand - AI Ethics Guideline 

กำรศึกษำและวิเครำะห์  

(Study and analysis) 

้ ได้ศึกษา 
่น ๆ  
่ได้รับการยอมรับทางด้านเทคโนโลยีหลาย ๆ แห่ง โดยพบว่าทุกประเทศและทุก
่สอดคล้องเป็นไปใน
่แต่ละประเทศหรือองค์กรก าหนด และก่อให้เกิดความ

เอกสารหลักการและแนวทางจริยธรรมปัญญาประดิษฐ์ของประเทศไทยฉบับนี
รวบรวม และวิเคราะห์หลักการและแนวทางจริยธรรมปัญญาประดิษฐ์ของประเทศอื
และองค์กรที
องค์กรต่างมีหลักการและแนวทางปฏิบัติทางจริยธรรมปัญญาประดิษฐ์ที
แนวทางเดียวกัน แต่ก็มีลักษณะเฉพาะที
แตกต่างกันโดยสรุป มีดังนี

้ คือ 

องค์กรเพื

่อความร่วมมือและพัฒนาทางเศรษฐกิจ หรือ โออีซีดี (Organization for 
Economic Co-operation and Development: OECD) ไ ด้ อ อ ก ค  า แ น ะ น  า ห ลั ก ก า ร ท า ง
่อถือ  
จริยธรรมของ AI ว่าการดูแลและให้บริการระบบปัญญาประดิษฐ์ควรมีความน่าเชื
สร้างประโยชน์ให้กับผู
่งยืน เคารพและไม่
้คนและโลกโดยท าให้เกิดความเจริญ การพัฒนาอย่างยั
กระท าการละเมิดต่อกฎหมาย สิทธิมนุษยชน ค่านิยมและความหลากหลายในระบอบ
่อรักษาไว้ซึ
ประชาธิปไตย สามารถเปิดให้มนุษย์สามารถเข้าไปแทรกแซงได้เมื
่ง
่อ
้งภาครัฐและเอกชนในการวิจัยและพัฒนาเพื
ความเป็นธรรมของสังคม เอื
กระตุ

้นให้เกิดนวัตกรรมปัญญาประดิษฐ์8 

้ออ านวยหน่วยงานทั

่อมีความจ าเป็น เพื

สหภาพยุโรป (Council of Europe) ได้ออกแนวทางเกี

่ยวกับปัญญาประดิษฐ์กับการ
่อาจส่งผลกระทบ
ป้องกันข้อมูลไว้ โดยกล่าวถึง การพัฒนาและน าปัญญาประดิษฐ์ไปประยุกต์ใช้ที
กับบุคคลและสังคม มีความจ าเป็นต้องมีการป้องกันเกียรติ (Dignity) ปกป้องสิทธิมนุษยชน 
์ในการป้องกันข้อมูล
(Human rights) เสรีภาพขั
่อปัญญาประดิษฐ์ถูกน าไปใช้ในกระบวนการ
ส่วนตัว (Personal data protection) โดยเฉพาะเมื

้นฐาน (Fundamental freedoms) และสิทธิ

้นพื

8 OECD Legal Instruments. Recommendation of the Council on Artificial Intelligence. May 22 2019. จาก 
https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449. 

1 | P a g e  

 
 
 
 
                                                           
Digital Thailand - AI Ethics Guideline 

้ องค์กรผู
้เชี

่ส าคัญ ควรสร้างกลไกที

้พัฒนาน าไปใช้ นอกจากนี

้ให้บริการระบบ
้ผลิตสินค้า ผู
ตัดสินใจ และเสนอให้ผู
่ยวชาญและสถาบันการศึกษาใน
ปัญญาประดิษฐ์ ควรรับค าปรึกษาจากคณะกรรมการอิสระ ผู
แขนงที
่อช่วยให้การออกแบบระบบปัญญาประดิษฐ์
่จะน าระบบปัญญาประดิษฐ์ไปใช้งาน เพื
ค านึงถึงสิทธิมนุษยชน (Human rights)  จริยธรรม และสังคม และช่วยในการตรวจสอบความเอน
่ท าให้หน่วยงานควบคุมดูแลการพัฒนาและการใช้งานระบบ
เอียงที
่เป็นอิสระ ส่งเสริมให้เกิดความร่วมมือระหว่าง
ปัญญาประดิษฐ์มีคณะกรรมการผู
หน่วยงานควบคุมดูแลการพัฒนาและใช้งานระบบปัญญาประดิษฐ์กับหน่วยงานอื
่มี
่นที
้บริโภค หน่วยงาน 
ความสามารถที
ที
่ยวข้องการห้ามเลือกปฏิบัติ (Anti-Discrimination) หน่วยงานก ากับดูแลในแขนงต่าง ๆ 
่เกี
รวมถึงหน่วยงานก ากับดูแลกิจการสื

่ยวข้องกับปัญญาประดิษฐ์ อาทิ หน่วยงานคุ

่ยวชาญที

้มครองผู

่อ9 

่เกี

้เชี

่น่าเชื

่อถือ คือ ปัญญาประดิษฐ์ต้องให้การสนับสนุนต่อมนุษย์ ดูแลสิทธิขั

คณะกรรมาธิการยุโรป (European Commission) กล่าวถึงแนวทางจริยธรรมส าหรับ
่อถือ ว่าควรให้เคารพต่อเสรีภาพของมนุษย์ ป้องกันภัยคุกคาม มีความเป็น
่ต้องการของระบบปัญญาประดิษฐ์ 
้นฐาน และอนุญาตให้
้นพื
่นคงปลอดภัยในทางเทคนิคของระบบ สามารถ
่อสร้างความ
้งก่อนและ
้ใช้งานเป็นศูนย์กลาง 
้ ไม่จ ากัดอายุ เพศ ความสามารถ 
้พิการควรได้รับความเท่าเทียมในการใช้งานเช่นเดียวกันกับบุคคล

ปัญญาประดิษฐ์ที
ธรรม และมีความสามารถในการอธิบายได้ และคุณสมบัติที
ที
่น่าเชื
มนุษย์ควบคุมดูแล มีความแข็งแกร่งและความมั
ป้องกันการคุกคามจากผู
รับผิดชอบและภาระความรับผิดชอบผลกระทบที
หลังการพัฒนา ให้บริการ ใช้งานระบบ และออกแบบโดยใช้หลักการที
โดยอนุญาตให้ผู
และคุณสมบัติ โดยเฉพาะผู
่วไป10  
ทั

้ไม่ประสงค์ดีได้ มีความโปร่งใส สามารถอธิบายได้ มีกลไกเพื

้ใช้งานในทุกระดับได้ใช้ผลิตภัณฑ์และบริการนี

่เกิดจากผลลัพธ์ของปัญญาประดิษฐ์ทั

่ให้ผู

9 Council of Europe. Guidelines on Artificial Intelligence and Data Protection. Consultative Committee of the Convention for the 
Protection of individuals with regard to Automatic Processing of Personal Data. Jan 25 2019. 
10 European Commission. Ethics Guidelines for Trustworthy AI. Apr 8 2019. จาก https://ec.europa.eu/digital-single-
market/en/news/ethics-guidelines-trustworthy-ai. 

2 | P a g e  

 
 
                                                           
Digital Thailand - AI Ethics Guideline 

่ปลอดภัย เพื

่อถือและความมั

่อรักษาความเป็นผู

่อนการพัฒนามาตรฐานทางเทคนิคที

ประธานาธิบดีโดนัลด์ ทรัมป์ ของประเทศสหรัฐอเมริกา ได้ออกค าสั

่งพิเศษ (Executive 
้น าด้านปัญญาประดิษฐ์ของสหรัฐอเมริกา โดยกล่าวว่าสหรัฐต้อง
Order) เพื
่เหมาะสมและลดอุปสรรคให้กับการทดสอบและ
ขับเคลื
่อเปิดให้เกิดการสร้างอุตสาหกรรมใหม่ๆ  
ให้บริการเทคโนโลยีปัญญาประดิษฐ์ที
่ยวข้องกับปัญญาประดิษฐ์และการน าปัญญาประดิษฐ์ไปใช้ในอุตสาหกรรมปัจจุบัน สนับสนุน
ที
่เกี
่นใจในเทคโนโลยีปัญญาประดิษฐ์ต่อสาธารณะ และป้องกัน
การสร้างความน่าเชื
สิทธิเสรีภาพ ความเป็นส่วนตัว และค่านิยมอเมริกันจากการใช้เทคโนโลยีปัญญาประดิษฐ์  
้งในปัจจุบันในอนาคตให้มีทักษะในการพัฒนาและ
โดยสหรัฐต้องให้การอบรมคนท างานทั
ประยุกต์ใช้เทคโนโลยีปัญญาประดิษฐ์ เพื
่อเตรียมความพร้อมส าหรับเศรษฐกิจในปัจจุบันและงาน
ในอนาคต ส่งเสริมการเข้าถึงข้อมูล โมเดล และทรัพยากรในการประมวลผลของรัฐบาลกลางสหรัฐ
ที
้นใน
่มีคุณภาพสูง และสามารถสืบย้อนได้อย่างสมบูรณ์ เพื
่นคงปลอดภัย ความเป็น
ด้านการวิจัยและพัฒนาปัญญาประดิษฐ์ ในขณะที
้งยังต้องลดอุปสรรค 
ส่วนตัว และความลับ ที
้ด้วย11 
ในการใช้งานปัญญาประดิษฐ์เพื

่สอดคล้องกับนโยบายและกฎหมายที
่อสนับสนุนนวัตกรรมที

่ยวข้อง อีกทั
่เกิดจากเทคโนโลยีปัญญาประดิษฐ์นี

่ยังคงรักษาความมั
่เกี

่มคุณค่าให้กับทรัพยากรเหล่านั

่อเพิ

้คนที

่นคงปลอดภัยของผู

้งหมดได้จริง ความมั

่ได้รับผลกระทบทั
่เกี
่น ๆ ที

่ยวข้องกับระบบปัญญาประดิษฐ์ ควรเป็นส่วนที

หน่วยงาน Smart Dubai ของนครดูไบ ได้ออกเอกสารหลักการและแนวทางจริยธรรม
่น ามาใช้งานควรเป็นตัวแทนของ
ปัญญาประดิษฐ์ โดยกล่าวถึงความเป็นธรรมของชุดข้อมูลที
้ใช้งาน  
่ปฏิบัติงาน ผู
ประชากรที
่ส าคัญในการออกแบบระบบ 
และบุคลลอื
่ร้ายแรง 
ควรมีความร่วมมือกันระหว่างประเทศต่าง ๆ เพื
(Lethal autonomous weapons) และอาวุธเหล่านั
้นควรได้รับการควบคุม ควรมีการร่วมมือกัน
ในการสร้างมาตรฐานด้านความปลอดภัยของระบบ  ส่วนการพัฒนาปัญญาประดิษฐ์ 
่อง (Recursively self-improving AI) ควรได้รับ
ที
่มีความสามารถปรับปรุงตนเองได้อย่างต่อเนื
่ยงอย่างเข้มข้น ควรให้การศึกษาแก่ประชาชนอย่าง
การเปิดเผย เฝ้าระวังและควบคุมความเสี
่อให้ประชาชนสามารถ
่อพัฒนาและให้ความรู
ต่อเนื

้ถึงการพัฒนาล่าสุดของปัญญาประดิษฐ์ เพื

่ยงการแข่งขันทางอาวุธอัตโนมัติที

่อหลีกเลี

่องเพื

11 The White House. Executive Order on Maintaining American Leadership in AI. Feb 11 2019. จาก 
https://www.whitehouse.gov/presidential-actions/executive-order-maintaining-american-leadership-artificial-intelligence/. 

3 | P a g e  

 
 
                                                           
Digital Thailand - AI Ethics Guideline 

่ยวกับข้อมูลและอัลกอริทึมที

่ผู
่ยนแปลงทางสังคมได้ ในขณะที

ปรับตัวเข้ากับการเปลี
ความโปร่งใสในการเปิดเผยเกี
และการรักษาไว้ซึ
่งทรัพย์สินทางปัญญา และภาครัฐควรสนับสนุนในการสร้างมาตรฐานที
ยอมรับโดยสากล (Internationally recognized standards) และแนวทางปฏิบัติที
(Best Practice) ส าหรับปัญญาประดิษฐ์ และควรก าหนดให้ต้องปฏิบัติตามอย่างเคร่งครัด12 

้ให้บริการระบบปัญญาประดิษฐ์เอง ควรมี
่ใช้งาน โดยไม่ขัดกับความเป็นส่วนตัว
่เป็นที
่ดีที

่สุด  

่งที

่งสามารถใช้โครงสร้างการก ากับดูแลที

คณะกรรมการป้องกันข้อมูลส่วนบุคคลของประเทศสิงคโปร์ ได้ออกกรอบการก ากับดูแล
ปัญญาประดิษฐ์ไว้ โดยกล่าวว่า ระบบปัญญาประดิษฐ์ต้องยืดมนุษย์เป็นศูนย์กลาง (Human 
่ได้รับ
Centric) การปกป้องความผาสุก (Well-beings) และความปลอดภัย (Safety) ควรเป็นสิ
่น า
การพิจารณาเป็นประการแรกในการออกแบบ พัฒนา และให้บริการปัญญาประดิษฐ์ องค์กรที
ปัญญาประดิษฐ์ไปให้บริการควรก าหนดรายละเอียดหลักการจริยธรรมไว้ในกระบวนการ
่งในผลิตภัณฑ์และบริการของตน และองค์กรควรก าหนดให้มี
ปฏิบัติงานหรือใช้เป็นข้อก าหนดหนึ
่อใช้ในการควบคุมดูแลการ ใช้งาน
โครงสร้างการก ากับดูแลภายในและการตรวจสอบเพื
้งโครงสร้าง 
่เดิมหรือจัดตั
ปัญญาประดิษฐ์ในองค์กร ซึ
้บริหารระดับสูง
ใหม่ก็ได้หากมีความจ าเป็น โดยได้รับการสนับสนุนจากคณะกรรมการบริหารและผู
 าเสมอและทุก
ขององค์กร ควรมีการทบทวนประสิทธิภาพของโครงสร้างการก ากับดูแลอย่างสม่
่ส าคัญ และองค์กรควรก าหนดนโยบายและกระบวนการใน
ครั
้ใช้งานตาม
่อให้สอดรับกับการเปลี
การปรับปรุงโมเดลอย่างสม่
้ การปรับปรุงโมเดลควร
ระยะเวลาและปรับปรุงโมเดลด้วยชุดข้อมูลการสอนที
่ยนแปลงไป และมี
ได้รับการด าเนินการเมื
การสื
่องมือทดสอบ
่อสารเพื
่ง่ายต่อการเข้าใจ โดยใช้เครื
่อทดสอบระบบต่าง ๆ อาทิ Fly Graph Readability 
ความสามารถในการท าความเข้าใจเพื
Formula, Gunning Fog Index, Flesh-Kincaid Readability tests เป็นต้น13 

่ทันสมัย นอกจากนี
่ยง และค่านิยมขององค์กรเปลี

่ยนโครงสร้างหรือบุคคลที
 าเสมอเพื

่ยนแปลงพฤติกรรมของผู

่อวัตถุประสงค์ ความเสี

่ออธิบายระบบกับผู

้ใช้งานด้วยภาษาที

้งมีการเปลี

่มีอยู

12 Smart Dubai. AI Ethics Principles & Guidelines. Version 1.6. Dec 30 2018. 
13 Personal Data Protection Commission, Singapore. A Proposed Model Artificial Intelligence Governance Framework. Jan 2019. 

4 | P a g e  

 
่
 
 
                                                           
Digital Thailand - AI Ethics Guideline 

องค์กรเพื

้ช่วยดิจิทัลที

่ยวข้องกับเพศของผู

่อช่วยป้องกันเทคโนโลยีผู

่อระบุความเสี
่เกี

่มีต่อพฤติกรรมของชายและหญิงทั
้นกับเด็กและเยาวชน สร้างเครื
่อสนับสนุนให้เกิดการสร้างโค๊ด ข้อมูล และโปรโตคอลเปิดที

่อการศึกษาวิทยาศาสตร์และวัฒนธรรมแห่งสหประชาชาติ (UNESCO) ร่วมกับ 
้ช่วย
่ให้ค าแนะน าเพื
่อตรวจสอบ
่ยงด้านความเอนเอียงทางเพศ และหาแนวทางในการแก้ไขหรือป้องกัน 
้งในโลก
่องมือ  
่อ
่ใช้เพื
่มีความอ่อนไหวทางเพศ ปรับปรุงเทคนิคในการ
่ยวกับเพศอย่างเป็นกลาง 
่งมี
่อเทียบกับเพศชาย สร้างกลไกภาระความรับผิดชอบที
่มีความเอนเอียงและละเมิดสิทธิส่วน

EQUALS Global Partnership ได้ออกบทความที
ดิจิทัลจากปัญหาความเอนเอียงทางเพศ โดยสร้างกลไกและบันทึกหลักฐานเพื
อัลกอริทึม เพื
ตรวจสอบอิทธิพลที
ออนไลน์และออฟไลน์ โดยเฉพาะผลกระทบที
กฎระเบียบและกระบวนการ เพื
การพัฒนาผู
สอนและอบรมผู
ให้การสนับสนุนการพัฒนาทักษะทางดิจิทัลกับทุกเพศอย่างเท่าเทียม โดยเฉพาะเพศหญิงซึ
จ านวนผู
เหมาะสมและควบคุมดูแลเพื
บุคคลต่าง ๆ14 

้พัฒนาระบบปัญญาประดิษฐ์ให้ตอบสนองต่อผู

้ช่วยดิจิทัลหรือระบบปัญญาประดิษฐ์ที

้มีทักษะทางดิจิทัลน้อยกว่าเมื

่อป้องกันหรือลดอัลกอริทึมที

้ใช้งานเกี

่เกิดขึ

บริษัท ไมโครซอฟท์ (Microsoft) ได้จัดท าหลักการและแนวทางจริยธรรมปัญญาประดิษฐ์
ในหลายประเภทซอฟต์แวร์ อาทิ ในภาพรวมของปัญญาประดิษฐ์ บริษัท ไมโครซอฟท์กล่าวถึง  
“The  Future  Computed,  Artificial  Intelligence  and  its  role in  society”  โ ด ย ร ะ บ บ
ปัญญาประดิษฐ์ควรให้บริการกับทุกคนด้วยความเป็นธรรมและไม่สร้างความแตกต่างในด้าน
่มคนที
่ในสถานการณ์เดียวกัน ข้อมูลชุดการสอนระบบต้องไม่มีความเอนเอียงไป
ผลลัพธ์กับกลุ
่งทั
่อใช้
ในทางใดทางหนึ
่คาดหวังไว้ และมีแนวทางในการ
งานด้วยกลุ
่มตัวแปรที
่อนไขการปฏิบัติงานจริง 
พิสูจน์ว่าระบบมีพฤติกรรมตามที
ปัญญาประดิษฐ์ต้องสอดคล้องกับกฎหมายคุ
่ก าหนดให้มีความโปร่งใสใน
่อ
การรวบรวม จัดเก็บ น าไปใช้ และการเผยแพร่ข้อมูล โดยเจ้าของข้อมูลมีสิทธิในการควบคุมเพื
เลือกได้ว่าข้อมูลของตนจะถูกใช้อย่างไร และสามารถอธิบาย ท าความเข้าใจถึงการท างาน  

่อยู
้งในด้านอายุ เพศ ลัทธิ ชนชาติ ปัญญาประดิษฐ์ควรได้รับการออกแบบเพื

่อนไขทางประสิทธิภาพที
้งใจและออกแบบไว้ภายใต้เงื
้มครองข้อมูลส่วนบุคคลที

่ชัดเจนภายใต้เงื
่ได้ตั

14 UNESCO and EQUALS Skills Coalition. I’d blush if I could: Closing gender divides in digital skills through education. 2019. จาก 
https://unesdoc.unesco.org/ark:/48223/pf0000367416. 

5 | P a g e  

 
่
 
                                                           
Digital Thailand - AI Ethics Guideline 

้ใช้งานสามารถตรวจพบและตระหนักถึงความเอนเอียง ความผิดพลาด และผลลัพธ์ที

่ได้รับผลกระทบจากระบบ 
้ที
้ใช้งานและผู
และปฏิสัมพันธ์กับข้อมูลของระบบปัญญาประดิษฐ์แก่ผู
่ไม่ได้
่อให้ผู
เพื
่อให้ค าแนะน าหรือคาดการณ์เหตุการณ์ ควรมี
ตั
้ใช้งานปัญญาประดิษฐ์เพื
่ผู
้งใจได้โดยง่าย ในกรณีที
้นเป็นอันดับต้นๆ เสมอ 15 และจริยธรรมใน
ภาระความรับผิดชอบส าหรับการตัดสินใจเหล่านั
ซอฟต์แวร์ประเภทจดจ าใบหน้า (Microsoft’s facial recognition) ไมโครซอฟท์ได้กล่าวถึง ความ
เท่าเทียม ความโปร่งใส การรับผิดชอบต่อผลกระทบ การไม่เลือกปฏิบัติ มีการแจ้งเตือนและต้อง
ได้รับความยินยอมจากเจ้าของข้อมูล และมีการสอดส่องอย่างถูกต้องตามกฎหมาย16 ในขณะที
ไมโครซอฟท์กล่าวถึงจริยธรรมในซอฟต์แวร์ประเภทสนทนาโต้ตอบอัตโนมัติ (Conversational 
AI) ไว้ว่า การพัฒนาปัญญาประดิษฐ์ต้องมีการก าหนดวัตถุประสงค์ของโปรแกรม ChatBot หรือ
่อสารกับมนุษย์ผ่านทาง
่อจ าลองบทสนทนาของมนุษย์ ให้สามารถพูดคุย สื
โปรแกรมที
เสียงหรือข้อความแบบ real-time โดยวัตถุประสงค์ของโปรแกรม ChatBot ต้องสอดคล้องกับ
่มีผลกระทบ
จริยธรรมและให้ความส าคัญ หากโปรแกรม ChatBot ถูกใช้เพื
่ได้รับจากการ
ส าคัญ จะต้องมีระบบตรวจสอบและตอบสนองต่อเรื
่อ่อนไหวหรือก้าวร้าวที
่ยวข้อง
่เกี
ปฏิสัมพันธ์กับผู
้เชี
ในการพัฒนาระบบที
่มีความอ่อนไหว อาทิ ข้อมูลทางการแพทย์ ข้อมูล
พนักงาน ข้อมูลทางการเงิน และการบังคับใช้กฎหมาย การพัฒนาระบบต้องสอดคล้องกับ
มาตรฐานหรือแนวทางด้านความสามารถในการเข้าถึงระบบที
่ยอมรับ  อาทิ  
ISO  40500:2012  (W3C  Web  Content  Accessibility  Guidelines:  (WCAG)  2.0)  แ ล ะ ใ ห้ 
้พิการหรือมีภาวะทุพพลภาพได้ร่วมทดสอบระบบด้วย17 
ผู

้ใช้งานอย่างเหมาะสม ระบบควรรับค าปรึกษาจากผู

่อสนับสนุนการท างานที

่ยวข้องกับข้อมูลที

่ยวชาญในแขนงที

่พัฒนาขึ

่ เป็นที

่องที

้นเพื

่เกี

15 Microsoft. The Future Computed, Artificial Intelligence and its role in society. Feb 2019. จาก https://3er1viui9wo30pkxh1v2nh4w-
wpengine.netdna-ssl.com/wp-content/uploads/2018/02/The-Future-Computed_2.8.18.pdf. 
16 Microsoft. Six principles to guide Microsoft’s facial recognition work. Dec 2018. จาก https://blogs.microsoft.com/on-the-
issues/2018/12/17/six-principles-to-guide-microsofts-facial-recognition-work/. 
17 Microsoft. Responsible bots: 10 guidelines for developers of conversational AI. Nov 2018. จาก https://www.microsoft.com/en-
us/research/uploads/prod/2018/11/Bot_Guidelines_Nov_2018.pdf. 

6 | P a g e  

 
่
 
 
 
                                                           
Digital Thailand - AI Ethics Guideline 

Beijing Academy of Artificial Intelligence (BAAI) เป็นองค์กรที

่ได้รับการสนับสนุน
โดยกระทรวงวิทยาศาสตร์และเทคโนโลยีของจีน ได้ออกหลักการทางจริยธรรมของ AI 
่มการส่งเสริมให้เกิดแพลตฟอร์มเปิดของ
เช่นเดียวกับประทศและองค์กรอื
่ยนประโยชน์ของการพัฒนา
่อหลีกเลี
ปัญญาประดิษฐ์เพื
ปัญญาประดิษฐ์และการต่อยอดอย่างต่อเนื
่เท่าเทียมกัน
่แตกต่างกัน18 
ในภูมิภาคและอุตสาหกรรมที

่อง สนับสนุนให้เกิดโอกาสในการพัฒนาที

่อท าให้เกิดการแลกเปลี

่ยงการผูกขาด เพื

่น ๆ และเพิ

ผลการศึกษาหลักการและแนวทางจริยธรรมปัญญาประดิษฐ์ต่าง ๆ เหล่านี

้ ถูกใช้เป็น
้องต้นในการจัดท าหลักการและแนวทางจริยธรรมปัญญาประดิษฐ์
หลักการและแนวความคิดเบื
้ใช้งานปัญญาประดิษฐ์
ของประเทศไทย โดยมุ
ท าการวิจัย ออกแบบ พัฒนา ให้บริการ และใช้งานปัญญาประดิษฐ์ได้โดยค านึงคุณธรรม จริยธรรม 
่อประโยชน์ต่อส่วนรวมเป็นส าคัญ 
สิทธิ เสรีภาพ ความเป็นมนุษย์ เพื

้ให้บริการและผู

้ออกแบบ ผู

่งหวังให้ผู

้พัฒนา ผู

้วิจัย ผู

18 Beijing AI Principles. May 5 2019. จาก https://www.baai.ac.cn/blog/beijing-ai-principles. 

7 | P a g e  

 
 
 
                                                           
Digital Thailand - AI Ethics Guideline 

8 | P a g e  

 
 
 
Digital Thailand - AI Ethics Guideline 

หลักกำรทำงจริยธรรมปัญญำประดิษฐ์ 

(AI Ethic Principles) 

1)  ความสามารถในการแข่งขันและการพัฒนาอย่างยั

่งยืน  (Competitiveness and 

Sustainability Development) 

•  ปัญญาประดิษฐ์ควรถูกสร้างและใช้งานเพื

่อสร้างประโยชน์และความผาสุกให้แก่

มนุษย์ สังคม เศรษฐกิจและสิ

่งแวดล้อมอย่างยั

่งยืน 

•  ปัญญาประดิษฐ์ควรถูกใช้งานเพื

่อเพิ
เจริญให้กับมนุษย์ สังคม ประเทศ ภูมิภาค และโลกอย่างเป็นธรรม 

่มความสามารถในการแข่งขันและสร้างความ

•  ปัญญาประดิษฐ์ควรได้รับการวิจัยและพัฒนาอย่างต่อเนื

่อง เพื

่อให้มนุษย์เกิดการ

สร้างสรรค์นวัตกรรมและอุตสาหกรรมใหม่ 

ปัญญาประดิษฐ์สามารถถูกสร้าง พัฒนา และใช้งานเพื

่อสร้างประโยชน์ให้กับ
้งในด้านการแพทย์ การเงิน อุตสาหกรรมการผลิตและการ
มนุษย์ในหลากหลายด้านทั
่อการคุกคามและเป็นภัยต่อมนุษย์ได้ด้วย
บริการ เป็นต้น แต่ก็สามารถใช้ปัญญาประดิษฐ์เพื
่ไม่
่ร้ายแรง และโปรแกรมคอมพิวเตอร์ที
่อพัฒนาอาวุธอัตโนมัติที
เช่นกัน เช่น การแข่งขันเพื
่งปัจจุบันในประเทศมหาอ านาจอย่างสหรัฐ จีน และรัสเซีย ได้มีการ
พึงประสงค์ เป็นต้น ซึ
่อสร้างอาวุธอัตโนมัติโดยใช้เทคโนโลยีปัญญาประดิษฐ์ออกมาในหลาย
วิจัยและพัฒนาเพื
ประเภทแล้ว ตัวอย่างเช่น บริษัทผลิตอาวุธ Kalashnikov ในรัสเซียได้ออกจ าหน่ายอาวุธ
่ใช้โครงข่ายประสาทเทียม (Neural 
้อัตโนมัติที
ชนิดใหม่ในปี 2560 เป็นโดรนต่อสู
่อระบุเป้าหมายและตัดสินใจได้ด้วยตนเอง19 เช่นเดียวกันกับ
Network) เป็นอัลกอริทึมเพื
่อการ
บริษัท ผลิตอาวุธหลายบริษัทของประเทศสหรัฐอเมริกาที
แยกแยะ ระบุวัตถุ และตัดสินใจแบบอัตโนมัติต่าง ๆ ในอาวุธของตนเอง20 เป็นต้น ดังนั
้น

่ใช้ปัญญาประดิษฐ์เพื

19 David Gilbert. Russian weapons maker Kalashnikov developing killer AI robots. Vice News. Jul 13 2017. จาก 
https://news.vice.com/en_us/article/vbzq8y/russian-weapons-maker-kalashnikov-developing-killer-ai-robots. 
20 Marcus Roth. AI in Military Drones and UAVs – Current Applications. Emerj. Jan 30 2019. จาก https://emerj.com/ai-sector-overviews/ai-
drones-and-uavs-in-the-military-current-applications/. 

9 | P a g e  

 
 
                                                           
 
Digital Thailand - AI Ethics Guideline 

การวิจัย พัฒนา และใช้งานปัญญาประดิษฐ์เพื
และเพิ
้พัฒนา ผู
ผู

่มการแข่งขันที

่งยืนให้กับมนุษย์ 
่อสร้างประโยชน์อย่างยั
้ออกแบบ 
้วิจัย ผู
่ผู
่สร้างสรรค์เป็นธรรม จึงควรเป็นหลักการส าคัญที

้ให้บริการ และหน่วยงานก ากับดูแลต่าง ๆ ควรค านึงถึง 

2)  ความสอดคล้องกับกฎหมาย จริยธรรม และมาตรฐานสากล (Laws Ethics and 

International Standards) 

•  ปัญญาประดิษฐ์ควรได้รับการวิจัย ออกแบบ พัฒนา ให้บริการ และใช้งาน 
สอดคล้องกับกฎหมาย บรรทัดฐาน จริยธรรม คุณธรรมของมนุษย์ และ
มาตรฐานสากล โดยเคารพต่อความเป็นส่วนตัว เกียรติ สิทธิเสรีภาพ และสิทธิ
มนุษยชน  

•  ออกแบบปัญญาประดิษฐ์ควรใช้หลักการมนุษย์เป็นศูนย์กลางและเป็นผู

้ตัดสินใจ 

•  ปัญญาประดิษฐ์ไม่ควรถูกใช้ในการก าหนดชะตาชีวิตของมนุษย์ 

่ยงที

่งใหม่ที

่เกิดขึ
้น จึงมีความสุ

่มเสี
่มนุษย์ในสังคมหนึ

้นจากการประมวลผลปัญญาประดิษฐ์อาจเป็นสิ

่หากน าผลลัพธ์เหล่านั
่งๆ ถือปฏิบัติ ซึ
้นมาได้ โดยเฉพาะในโลกโซเชียลมีเดียที

ผลลัพธ์ที
ที
่มนุษย์เคยสร้างขึ
กฎหมายและจริยธรรมที
ขัดแย้งทางสังคมขึ
เผยแพร่ออกไปได้อย่างรวดเร็ว กรณีตัวอย่างที
ปี 2561 เมื
สัญญากับกระทรวงกลาโหมสหรัฐอเมริกา เพื
ใช้ในการวิเคราะห์วีดีโอจากโดรนเพื
่องจากเห็นว่าเป็นการกระท าที
เนื
และมีพนักงานกว่า 12 คนลาออกจากบริษัทจากเหตุการณ์ดังกล่าว21  

่แตกต่างจาก
้นไปใช้งานแล้วจะขัดต่อข้อ
่งอาจก่อให้เกิดปัญหาความ
่ข้อมูลข่าวสารสามารถถูก
้นกับบริษัท Google ในเดือนเมษายน 
่บริษัทท า
่อน าเทคโนโลยีปัญญาประดิษฐ์ของบริษัทไป
่เป็นมนุษย์ 
่น าเทคโนโลยีปัญญาประดิษฐ์ไปใช้โดยผิดต่อศีลธรรม 

่อมีพนักงานของบริษัทกว่า 3,000 คน ท าการประท้วงต่อเหตุการณ์ที

่อระบุต าแหน่งและสังหารเป้าหมายที

่เกิดขึ

21 Kate Conger. Google Employees Resign in Protest Against Pentagon Contract. GIZMODO. May 14 2018. จาก 
https://gizmodo.com/google-employees-resign-in-protest-against-pentagon-con-1825729300. 

10 | P a g e  

 
 
 
                                                           
 
3)  ความโปร่งใสและภาระความรับผิดชอบ (Transparency and Accountability) 

Digital Thailand - AI Ethics Guideline 

•  ปัญญาประดิษฐ์ควรได้รับการวิจัย ออกแบบ พัฒนา ให้บริการและใช้งาน  
ด้วยความโปร่งใส สามารถอธิบายและคาดการณ์ได้ รวมถึงสามารถตรวจสอบ
กิจกรรมต่าง ๆ ที

้นย้อนหลังได้ 

่เกิดขึ

•  ปัญญาประดิษฐ์ควรมีความสามารถในการสืบย้อนกลับ (Traceability) เฝ้าระวัง 
ตรวจสอบความผิดปกติและวินิจฉัยปัญหาความล้มเหลวได้ (Diagnosability) ได้  

•  ผู

้ออกแบบ ผู

้ให้บริการและผู

้พัฒนา ผู
้วิจัย ผู
ความรับผิดชอบ (Accountability) ต่อผลกระทบที
ตามภาระหน้าที

่ของตน 

้ใช้งานปัญญาประดิษฐ์ ควรมีภาระ
้นจากปัญญาประดิษฐ์

่เกิดขึ

่เกี

้นสูงที

่เกิดขึ

่บ้าง ซึ

้รับบริการและบุคคลที

้น ๆ สามารถส่งผลกระทบกับผู

ด้วยปัญญาประดิษฐ์เป็นเทคโนโลยีชั

้นจะมีความแตกต่างกันในแต่ละโมเดลและอัลกอริทึมที

่วไปจะเข้าใจกลไกการ
่ยากส าหรับคนทั
้น แต่ผลลัพธ์จากการ
ท างาน และแม้ว่าในปัจจุบันปัญญาประดิษฐ์จะมีความแม่นย ามากขึ
่งอัตราความ
ประมวลผลปัญญาประดิษฐ์ในโมเดลต่าง ๆ ก็ยังคงมีความผิดพลาดอยู
่ใช้งาน  
ผิดพลาดที
่อมีการน าผลลัพธ์ของการตัดสินใจจากปัญญาประดิษฐ์มาใช้ตัดสินผลใด ๆ ผลการ
แต่เมื
ตัดสินใจนั
้งแต่ระดับ
เล็กน้อยจนถึงระดับร้ายแรง และหากเกิดผลกระทบจากการตัดสินใจโดยปัญญาประดิษฐ์
ขึ
่ต้องด าเนินการถัดไป หากเกิด
้นจริง การระบุผู
้ได้รับผลกระทบอาจเกิดความเคลือบแคลงสงสัย
เหตุการณ์ที
ถึงหลักการและเหตุผลที
่ยวข้อง
้น หากกระบวนการวิจัย พัฒนา  
่อาจเกิดขึ
กับผู
่อหา
และให้บริการปัญญาประดิษฐ์ไม่มีความโปร่งใส และปราศจากกลไกในการสืบย้อนเพื
่นในการใช้งานปัญญาประดิษฐ์ได้ 
ผู
้รับผิดชอบแล้ว อาจส่งผลกระทบต่อความเชื
่นคงปลอดภัย
ตัวอย่างเช่น รายงานผลการใช้งานปัญญาประดิษฐ์ในผลิตภัณฑ์ด้านความมั
่ออกโดย Osterman Research ในเดือนธันวาคม ปี 2561 พบว่าร้อยละ 54 
ทางไซเบอร์ที

่ปัญญาประดิษฐ์ใช้ในการตัดสินใจ และจะเกิดค าถามที
้น ดังนั

่ต้องรับผิดชอบจะเป็นกระบวนการที
้ที
้นจริง ผู

่ต้องรับผิดชอบต่อผลกระทบที
้ที

่ก่อให้เกิดผลกระทบขึ

่ยวข้องได้ตั

่อมั

่เกี

11 | P a g e  

 
Digital Thailand - AI Ethics Guideline 

้ตอบแบบสอบถาม ตอบว่าผลลัพธ์การป้องกันและตรวจสอบจากผลิตภัณฑ์ไม่มีความ
ของผู
แม่นย า และร้อยละ 47 ตอบว่าผลิตภัณฑ์มีการตรวจสอบผิดพลาด (False Positive)22   

4)  ความมั

่นคงปลอดภัยและความเป็นส่วนตัว (Security and Privacy) 

•  ปัญญาประดิษฐ์ควรถูกสร้างเพื

่อบริการ แต่ไม่ควรถูกใช้เพื

่อหลอกลวง ต่อต้าน 

และคุกคามมนุษย์ 

•  ปัญญาประดิษฐ์ควรได้รับการออกแบบโดยใช้หลักการป้องกันความเสี

่อ
่ยง เพื
่นคงปลอดภัยของข้อมูล
่งความมั
้มครองข้อมูล ส่วนบุคคล จริยธรรม และความปลอดภัย
่งแวดล้อมภายนอกตลอดวัฏจักรชีวิตของระบบ มีความสามารถใน

ป้องกันการโจมตีจากภัยคุกคาม เพื
และระบบ รวมถึงการคุ
ของชีวิตและสิ
การตรวจสอบ รายงานและตอบสนองเพื

่ยงหรือลดผลกระทบ 

่อรักษาไว้ซึ

่อหลีกเลี

•  ปัญญาประดิษฐ์ควรมีกลไกให้มนุษย์แทรกแซงระบบเพื

่อควบคุมความเสี

่ยงที

่อาจมี

ผลกระทบกับมนุษย์ได้ 

•  หน่วยงานรัฐควรวางแผนก ากับดูแลการพัฒนาและให้ความร่วมมือกับนานาชาติใน
่ยงการแข่งขันสร้างอาวุธอัตโนมัติจากปัญญาประดิษฐ์ที

การหลีกเลี

่ร้ายแรง 

เนื

่องจากในกระบวนการวิจัย ออกแบบและพัฒนาปัญญาประดิษฐ์จ าเป็น  
ต้องมีการน าเข้าชุดข้อมูล ประมวลผล จัดเก็บ และเผยแพร่หรือส่งต่อผลลัพธ์จาก  
การประมวลผลข้อมูล ซึ
่มีความอ่อนไหว  
่งในหลายครั
้ไม่ประสงค์ดีแล้ว อาจสร้าง
เป็นความลับ หรือเป็นข้อมูลส่วนตัว ซึ
ผลกระทบต่อเจ้าของข้อมูล องค์กร รวมถึงผู
่มีส่วนได้เสียได้ ตัวอย่างในเดือนเมษายน  
้ที
้ไม่ประสงค์ดีสามารถเข้าถึงข้อมูลบัตรเครดิต ของลูกค้ากว่า 1 แสน
่ผู
ปี 2561 กรณีที
รายการของห้างสรรพสินค้า Sears และสายการบินเดลต้าไลน์ โดยอาศัยโปรแกรมไม่พึง
่23 
ประสงค์ที

้งข้อมูลเหล่านี
่งหากถูกเข้าถึงโดยผู

่เข้าถึงระบบ Chatbot ของบริษัท [24]7.ai ซึ

้งสองใช้บริการอยู

้เป็นข้อมูลที

่งบริษัททั

22 Osterman Research White Paper. The State of AI in Cybersecurity: The Benefits, Limitations and Evolving Questions. Dec 2018. 
23 Abigail Abrams. Data Breach at Sears and Delta May Have Hit ‘Several Hundred Thousand’ Customers. TIME USA, LLC. Apr 6 2018. 
จาก https://time.com/5230288/delta-sears-data-breach-credit-cards/. 

12 | P a g e  

 
 
                                                           
Digital Thailand - AI Ethics Guideline 

่ เกิดขึ

่วโมง เนื

่ยวกับนาซีและยิว รวมถึงข้อความเรื

้นการออกแบบและพัฒนาปัญญาประดิษฐ์ยังต้องค านึงถึง การป้องกันภัยคุกคามระบบ
ดังนั
้นกับโปรแกรม  
่ไม่พึงประสงค์ด้วย ตัวอย่างหนึ
่อป้องกันมิให้เกิดผลลัพธ์ที
่งที
เพื
่งถูกออกน ามาใช้ในปี 2559 และต้องปิดการ
Tay Chatbot ของบริษัทไมโครซอฟท์ ซึ
่องจากมีการตรวจสอบพบว่ามีการโพสต์
ให้บริการลงภายในเวลาเพียง 16 ชั
่ไม่
่อง เพศสัมพันธ์ในทางที
ข้อความที
่มีความรุนแรงเกี
้ไม่ประสงค์ดีในโลกโซเชียล
่ระบบถูกสอนจากผู
่งเป็นผลอันเนื
สุภาพ ซึ
มีเดีย24 ดังนั
้น การออกแบบและพัฒนา ปัญญาประดิษฐ์จึงควรค านึงถึงหลักการรักษา
่อาจเกิดกับ 
ความมั
ตัวระบบปัญญาประดิษฐ์เอง และควรมีกลไกให้มนุษย์สามารถแทรกแซกการด าเนินการต่าง ๆ 
่ผิดพลาด และการน า
เพื
ปัญญาประดิษฐ์ไปใช้ในทางที
่อคุกคามมนุษย์หรือ ผลิตอาวุธ
่ร้ายแรง  
อัตโนมัติที

่นคงปลอดภัยและการป้องกันข้อมูล ส่วนตัว รวมถึงภัยคุกคามที

้ไม่ประสงค์ดี การประมวลผลที

่ยงจากการคุกคามผู

่งรวมถึงการใช้เพื

่องมาจากการที

่อลดความเสี

่ผิด ซึ

5)  ความเท่าเทียม หลากหลาย ครอบคลุม และเป็นธรรม (Fairness) 

•  การออกแบบและพัฒนาปัญญาประดิษฐ์ควรค านึงถึงความหลากหลาย หลีกเลี

การผูกขาด ลดการแบ่งแยกและเอนเอียง เพื
่จะท าได้ โดยเฉพาะกลุ
มากเท่าที

่อก่อให้เกิดประโยชน์ต่อผู
้ด้อยโอกาสในสังคม (Diversity) 

่มคนผู

่ยง
้คนจ านวน

•  การตัดสินใจที
่เกี
่ยวข้องกับวิจัย ออกแบบ พัฒนา ให้บริการ และใช้งาน
่ส าคัญควรสามารถพิสูจน์ถึงความเป็นธรรมได้ (Fairness) 
ปัญญาประดิษฐ์ที

ผลลัพธ์จากการประมวลผลปัญญาประดิษฐ์อาจมีความไม่เป็นธรรมได้ 
่ถูกน ามาใช้ในการสอน ทดสอบ และพิสูจน์มีความเอนเอียง และไม่เป็น
หากชุดข้อมูลที
่จะได้รับผลกระทบจากการใช้งานอย่างครอบคลุมและเท่าเทียม งานวิจัย
ตัวแทนของ ผู
้ที
่อเดือนเมษายน ปี 2562 พบปัญหาความ
ล่าสุดของศูนย์วิจัยมหาวิทยาลัย New York เมื

24 Sarah Perez. Microsoft silences its new A.I. bot Tay, after Twitter users teach it racism. Verizon Media. Mar 24 2016. จาก 
https://techcrunch.com/2016/03/24/microsoft-silences-its-new-a-i-bot-tay-after-twitter-users-teach-it-racism/. 

13 | P a g e  

 
 
                                                           
  
Digital Thailand - AI Ethics Guideline 

้อชาติในงานวิจัย ออกแบบ และพัฒนาปัญญาประดิษฐ์ที

่ได้รับ
้วิจัยด้านปัญญาประดิษฐ์เป็นเพศ
้นน าด้านปัญญาประดิษฐ์อย่าง  Facebook และ Google  
่เพียงร้อยละ 15 และร้อยละ 10 ตามล าดับ 
่เป็นเพศหญิงอยู
้วิจัยพบว่าในบริษัท Facebook และ Google มีผู
้วิจัยด้านปัญญาประดิษฐ์
่เพียงร้อยละ 4 และร้อยละ 2.5 ตามล าดับ25 ผลกระทบจากปัญหาด้าน
้ ยกตัวอย่างเช่น อัลกอริทึมปัญญาประดิษฐ์ในโปรแกรม COMPAS  
่ถูกใช้งานโดยศาลในสหรัฐ ได้รับการตรวจสอบพบว่าระบบ 
 ามากกว่า
่จะตัดสินว่า จ าเลยผิวด ามีโอกาสจะเป็นผู
่งจากงานวิจัยของ M.I.T Media Lab ในปี 2562 พบว่า
่อ Rekognition มีความยากล าบากในการจ าแนก
่มีผิวสีด าในรูปภาพมากกว่าเทคโนโลยีของบริษัท  IBM  
้ที
่จ าแนกคนผิวด า
่งานวิจัย ออกแบบ 
่งที
้วิจัย ชุดข้อมูล และสามารถพิสูจน์ถึง 

เอนเอียงในทางเพศและเชื
การเผยแพร่จ านวนมาก โดยพบว่ากว่าร้อยละ 80 ของผู
ชาย และยังพบว่าในบริษัทชั
้วิจัยด้านปัญญาประดิษฐ์ที
มีผู
ในด้านเชื
้อชาติผู
่เป็นคนผิวด าอยู
ที
ความเอนเอียงนี
ของบริษัท Northpointe ที
มีความเอนเอียงไปในทางที
จ าเลยผิวขาว และอีกตัวอย่างหนึ
เทคโนโลยีจดจ าใบหน้าของ Amazon ชื
ใบหน้าของสตรี และผู
และไมโครซอฟท์26 รวมถึงโปรแกรม Photo ของ Google ในปี 2558 ที
ผิดพลาดว่าเป็น ลิงกอลิร่า27 เป็นต้น ดังนั
และพัฒนา จะต้องค านึงถึงความหลากหลายของผู
ความเป็นธรรมของระบบได้ 

้นจึงมีความจ าเป็นอย่างยิ

้กระท าผิดซ้

25 Sarah Myers West., Meredith Whittaker., and Kate Crawford. Discrimination Systems: Gender, Race, and Power in AI. AINOW Institute. 
Apr 2019. จาก https://ainowinstitute.org/discriminatingsystems.pdf. 
26 Natasha Singer. Amazon Is Pushing Facial Technology That a Study Says Cloud Be Biased. The New York Times. Jan 24 2019. จาก 
https://www.nytimes.com/2019/01/24/technology/amazon-facial-technology-study.html. 
27 Sophie Curtis. Google Photos labels black people as ‘gorillas’. The Telegraph. Jul 01 2015. จาก 
https://www.telegraph.co.uk/technology/google/11710136/Google-Photos-assigns-gorilla-tag-to-photos-of-black-people.html. 

14 | P a g e  

 
 
 
 
                                                           
Digital Thailand - AI Ethics Guideline 

6)  ความน่าเชื

่อถือ (Reliability) 

•  ปัญญาประดิษฐ์ควรได้รับการสนับสนุนให้มีความน่าเชื

่อถือและความมั

่นใจในการ

ใช้งานต่อสาธารณะ  

•  ปัญญาประดิษฐ์ควรสามารถคาดการณ์ ตัดสินใจ และให้ค าแนะน าได้อย่างแม่นย า
่อต้องการ 
่สามารถเชื

่อถือได้และสร้างใหม่ได้เมื

ถูกต้อง (Accuracy) สร้างผลลัพธ์ที
(Reliability and Reproducibility) 

•  ปัญญาประดิษฐ์ควรมีการควบคุมคุณภาพและตรวจสอบความครบถ้วนสมบูรณ์

ของข้อมูล (Quality and integrity of data) 

•  ปัญญาประดิษฐ์ควรมีกระบวนการและช่องทางรับผลสะท้อนกลับ (Feedback) 
่องร้องเรียน 
้ใช้งานสามารถแจ้งความต้องการเพิ
่ตรวจสอบพบ  และให้ข้อเสนอแนะได้โดยง่ายและรวดเร็ว 

่อให้ผู
้ใช้งาน เพื
จากผู
แจ้งปัญหาของระบบที

่มเติม รับเรื

่ใช้ในผลิตภัณฑ์ด้านความมั

้นหากปัญญาประดิษฐ์สร้างผลลัพธ์ที

เนื
้รับบริการได้ ดังนั

่นของระบบได้ ดังจะเห็นได้จากตัวอย่างทั

่องจากผลลัพธ์จากการประมวลผลของปัญญาประดิษฐ์สามารถสร้างผลกระทบ
่ไม่ถูกต้องก็จะส่งผลต่อความ 
ให้กับ ผู
้งในกรณีของความผิดพลาดจากการ 
เชื
่อมั
่นคงปลอดภัย 
ตรวจสอบภัยคุกคามในระบบปัญญาประดิษฐ์ที
ทางไซเบอร์ ความผิดพลาดจากการประมวลผลภาพในโปรแกรม Photo ของ Google อีก
่งในกรณีของระบบจดจ าใบหน้าของ  Amazon Rekognition ในปี 2561 
ตัวอย่างหนึ
พบว่ามีความผิดพลาดในการระบุภาพของสมาชิกสภาคอนเกรสของสหรัฐจ านวน  28 คน
่ถูกจับในข้อหาอาชญากรรม 28 เป็นต้น ดังนั
่นให้กับ 
้ที
ว่าเป็นผู
้งจากการควบคุมด้านกระบวนการวิจัย ออกแบบ พัฒนา การควบคุม
ปัญญาประดิษฐ์ทั
่น ามาใช้งาน และการปรับปรุงคุณภาพของ ระบบจากผลสะท้อนกลับ
คุณภาพของข้อมูลที
้ใช้งาน จึงเป็นสิ
ของผู
่ถูกต้องแม่นย าและ
่งที
้ใช้งาน 
เชื

่อให้ระบบสามารถให้ค าแนะน าที

้นการสร้างความเชื

่อถือได้กับผู

่ส าคัญ เพื

่อมั

28 Jacob Snow. Amazon’s Face Recognition Falsely Matched 28 Members of Congress With Mugshots. American Civil Liberties Union. Jul 
26 2018. จาก https://www.aclu.org/blog/privacy-technology/surveillance-technologies/amazons-face-recognition-falsely-matched-28. 

15 | P a g e  

 
 
                                                           
Digital Thailand - AI Ethics Guideline 

16 | P a g e  

 
 
 
Digital Thailand - AI Ethics Guideline 

แนวทำงปฏิบัติทำงจริยธรรมปัญญำประดิษฐ์  

(AI Ethic Guidelines)  

1)  หน่วยงานรัฐและหน่วยงานก ากับดูแล 

•  ความสามารถในการแข่งขันและการพัฒนาอย่างยั

่งยืน (Competitiveness 

and Sustainability Development) 
o  ควรตรวจสอบและประเมินงานวิจัย พัฒนาและการน าปัญญาประดิษฐ์ไปใช้งาน 
ว่าสามารถสร้างให้เกิดประโยชน์และความผาสุกต่อมนุษย์ สังคม  และ
่งแวดล้อม 
สิ

o  ควรสนับสนุนการวิจัยและพัฒนาในการน าปัญญาประดิษฐ์มาใช้ให้เกิด

ประโยชน์ 

o  ควรส่งเสริมและสนับสนุนการท างานร่วมกันระหว่างมนุษย์แ ละ

ปัญญาประดิษฐ์ที

่ท าให้เกิดประโยชน์ต่อมนุษย์ 

o  ควรส่งเสริมและสนับสนุนให้หน่วยงานต่าง ๆ สามารถเข้าถึงองค์ความรู

ปัญญาประดิษฐ์ ด้วยเทคโนโลยีโครงสร้างพื
เพื
และพัฒนา 

่อให้เกิดการแลกเปลี

่ยนข้อมูลความรู

้ทาง
้นฐานทางดิจิทัลและกลไกต่าง ๆ 
้ และเทคโนโลยีในการวิจัย ออกแบบ 

o  ควรเฝ้าระวังและติดตามการใช้งานปัญญาประดิษฐ์ต่อผู

้ใช้งาน ว่าก่อให้เกิด

ประโยชน์ได้จริงและไม่สร้างผลกระทบในเชิงลบ 

o  หน่วยงานรัฐ 

▪  ควรออกนโยบายเพื

่อกระตุ

่อสนับสนุนให้หน่วยงานทั

้งภาครัฐและเอกชน
้นให้เกิดนวัตกรรมปัญญาประดิษฐ์
ด าเนินการวิจัยและพัฒนา เพื
่ช่วยในการสร้างอุตสาหกรรมใหม่ควรส่งเสริมและสนับสนุนด้าน
ที
่ยวกับ
่วไปเพื
การศึกษา อบรมประชาชนทั
ปัญญาประดิษฐ์ และผลกระทบที
้นจากปัญญาประดิษฐ์  
สร้างทัศนคติที
่ถูกต้องในการยอมรับการใช้งานเทคโนโลยี
่ก่อให้เกิดประโยชน์ และทัศนคติของการตระหนักรู
ปัญญาประดิษฐ์ที
ภัยคุกคามจากปัญญาประดิษฐ์ควรสร้างความร่วมมือกับองค์กร

่อให้มีความรู
่อาจเกิดขึ

้ และทักษะเกี

17 | P a g e  

 
 
้
Digital Thailand - AI Ethics Guideline 

ภายในประเทศ  ภูมิภาคและนานาชาติ เพื
ปัญญาประดิษฐ์ที
ระดับโลก 

่อพัฒนาโครงการ
่ก่อให้เกิดประโยชน์ต่อภาพรวมในระดับภูมิภาคและ

• ความสอดคล้องกับกฎหมาย จริยธรรม และมาตรฐานสากล (Laws Ethics 

and International Standards) 
o  ควรสนับสนุนการให้การศึกษาเพื

่อสร้างความตระหนักรู
ในปัญญาประดิษฐ์และผลกระทบของปัญญาประดิษฐ์ให้กับผู
้วิจัย และพัฒนาปัญญาประดิษฐ์ เพื
การอบรมผู
ผลกระทบของระบบปัญญาประดิษฐ์ที
สนับสนุนงานวิจัยเกี

้และความเข้าใจ 
้ใช้งาน สนับสนุน
่อให้ตระหนักและเข้าใจ
่มีต่อบุคคลและสังคม และให้การ

่ยวกับปัญญาประดิษฐ์กับสิทธิมนุษยชน 

o  การจัดซื

้พัฒนา และผู

้อจัดจ้างควรก าหนดให้ผู

้ให้บริการปัญญาประดิษฐ์  
ต้องด าเนินการสอดคล้องกับหลักเกณฑ์ของความโปร่งใส มีการประเมินผล
กระทบ จากการประมวลผลข้อมูลต่อสิทธิมนุษยชนและความเป็นส่วนตัว 
้นกับ
พร้อมก าหนดภาระความรับผิดชอบต่อผลกระทบเชิงลบที
ปัญญาประดิษฐ์ 

่เกิดขึ

o  หน่วยงานรัฐ 

่อเพิ

่อถือให้กับผู

่มความน่าเชื

▪  ควรสนับสนุนในการสร้างมาตรฐานให้เป็นที
่ดีที

่ยอมรับโดยสากล  
้ออกแบบ 
่สุด (Best Practice) และก าหนดให้ผู
้ให้บริการต้องปฏิบัติตาม พร้อมกลไกการให้ใบรับรอง 
้ออกแบบ 

และแนวทางปฏิบัติที
ผู
้พัฒนา และผู
ส าหรับปัญญาประดิษฐ์ เพื
้พัฒนา และผู
ผู

้ให้บริการ รวมถึงผลิตภัณฑ์และบริการที
▪  ควรสนับสนุนให้มีองค์กรต่าง ๆ มีหน่วยงานก ากับดูแลการพัฒนาและ
้พัฒนา 
่ยวกับผลกระทบด้านกฎหมาย 
่มีผลระทบเชิงลบ
้วิจัย 

ใช้งานปัญญา ประดิษฐ์เพื
และผู
จริยธรรม และสิทธิมนุษยชน ประเมินความเสี
ของระบบ และดูแลด้านการสร้าง ภาระความรับผิดชอบของผู
้ออกแบบ ผู
ผู

้ให้บริการปัญญาประดิษฐ์ เกี

้ให้บริการปัญญาประดิษฐ์ 

่อให้ค าปรึกษาผู

้พัฒนา และผู

้ออกแบบ ผู

่ยวข้อง 

้วิจัย ผู

่ยงที

่เกี

18 | P a g e  

 
 
 
Digital Thailand - AI Ethics Guideline 

• ความโปร่งใสและภาระความรับผิดชอบ (Transparency and Accountability) 
o  หน่วยงานก ากับดูแลการพัฒนาและใช้งานปัญญาประดิษฐ์ควรตรวจสอบความ
้พัฒนาใช้ใน
้วิจัย ผู
่ผู
โปร่งใสของโมเดลและอัลกอริทึมที
ปัญญาประดิษฐ์ โดยใช้หลักการเรื
่องความสามารถในการอธิบายได้ 
่ 
่มา และหน้าที
(Explainable) ซึ
การท างานในการคาดการณ์ต่าง ๆ รวมถึงสามารถอธิบายวิธีการสอน  
และคัดเลือกโมเดลได้ 

่น ามาใช้ต้องสามารถอธิบายที

้ออกแบบ  และผู

่งอัลกอริทึมที

้ใช้งานขึ

้น โดยก าหนดให้ผู

o  หน่วยงานก ากับดูแลการพัฒนาและใช้งานปัญญาประดิษฐ์ควรก าหนดนโยบาย
้วิจัย 
่อแสดง
่มี
้ใช้งานที
่อรองรับผู
่แตกต่างกันของการน าไปใช้ 
่อาจได้รับผลกระทบ 
้ที

ด้านการให้ค าอธิบายปัญญาประดิษฐ์กับผู
ออกแบบ และพัฒนาปัญญาประดิษฐ์ สร้างเอกสารทางเทคนิคเพื
รายละเอียดออกแบบ และการท างานในหลายมุมมอง เพื
ความรู
้ความเข้าใจที
และก าหนดให้มีช่องทางที
ส่งการร้องขอค าการอธิบายเหล่านี

่แตกต่างกัน และสถานการณ์ที

่ง่ายและรวดเร็วเพื

่อให้ ผู

้ได้ 

้ให้บริการและผู

o  ควรมีกลไกเพื
่อสร้างภาระความรับผิดชอบ (Accountability) ของผู
้วิจัย 
้พัฒนา ผู
่มี 
้ที
้ใช้งานปัญญาประดิษฐ์ รวมถึงผู
ผู
้ออกแบบ ผู
่น ๆ ตลอดวัฏจักรชีวิตของระบบ โดยมีกระบวนการในการ
ส่วนได้เสียอื
ตรวจสอบชุดข้อมูล อัลกอริทึม กระบวนการออกแบบ การน าไปใช้  
้งการตรวจสอบภายในและ
และผลลัพธ์ของการใช้งานปัญญาประดิษฐ์ ทั
ภายนอกอย่างอิสระ การรายงานผลการตรวจสอบ การประเมินความเสี
่ยงเชิงลบ 
่ยง ผลกระทบเชิงลบของปัญญาประดิษฐ์ 
และการด าเนินการเพื
่อลดหรือหลีกเลี
่งแวดล้อม 
โดยเฉพาะผลกระทบต่อมนุษย์และสิ

o  ก าหนดผู
เสียหายที

้รับผิดชอบในการสืบสวน และแก้ไขสาเหตุของความสูญเสียและ
่เกิดขึ

้น จากปัญญาประดิษฐ์ 

• ความมั

่นคงปลอดภัยและความเป็นส่วนตัว (Security and Privacy) 

o  ควรก าหนดนโยบายและมาตรฐานทางเทคนิคด้านความมั
้มครองความเป็นส่วนตัวส าหรับปัญญาประดิษฐ์  เพื

การคุ
ป้องกันภัยคุกคามของปัญญาประดิษฐ์ ที

่นคงปลอดภัยและ
่อลดช่องโหว่และ
่ก่อให้เกิดผลกระทบในด้านความลับ 

19 | P a g e  

 
 
Digital Thailand - AI Ethics Guideline 

ความครบถ้วนถูกต้อง ความพร้อมใช้ของข้อมูล การคุ
รวมถึงผลกระทบด้านจริยธรรม ชีวิตและสิ
พัฒนา และให้บริการปฏิบัติตาม 

่งแวดล้อม และให้ผู

้มครองข้อมูลบุคคล 
้วิจัย ออกแบบ 

o  หน่วยงานก ากับดูแลการพัฒนาและใช้งานปัญญาประดิษฐ์ ควรด าเนินการ
่ยงและควบคุมภายใน  
่ยง ก าหนดวิธีการจัดการความเสี
่ยวข้องกับปัญญาประดิษฐ์ หาแนวทาง 
่เกี
่ยง ตรวจสอบและรายงาน ประสิทธิภาพในการจัดการ

่จัดการความเสี

่ยงที

จัดการความเสี
เพื
่อท าหน้าที
ในการจัดการความเสี
ความเสี
้งนี
ทั
ตลอดวัฏจักรชีวิตของระบบ รวมถึงเมื
โดยด าเนินการอย่างน้อยปีละ 1 ครั

่ยง ทบทวนและปรับปรุงแนวทางและกระบวนการจัดการความเสี

้ควรก าหนดให้มีการด าเนินการจัดการความเสี

่ยง อย่างสม่

่ยง  
 าเสมอ  
้ อถอนระบบ  
้น 

่ส าคัญเกิดขึ

่อจ าเป็นต้องรื
่ยนแปลงที

้งหรือมีการเปลี

่ยงเชิงลบที

o  หน่วยงานก ากับดูแลการพัฒนาและใช้งานปัญญาประดิษฐ์ควรประเมินความ
่กระทบกับบุคคลและสังคมจากการเพิกเฉยข้อมูลหรือ
่เพิกเฉย
้นตอน การพัฒนา

เสี
สถานะการณ์เฉพาะ (De-contextualised data)29 และอัลกอริทึมที
กับบริบทหรือสถานะการณ์เฉพาะอย่างเพียงพอระหว่างขั
และน าปัญญาประดิษฐ์ไปใช้งาน 

o  หน่วยงานก ากับดูแลการพัฒนาและใช้งานปัญญาประดิษฐ์ควรด าเนินการ
ประเมินระดับการเข้าแทรกแซงปัญญาประดิษฐ์โดยมนุษย์ในกระบวนการต่าง ๆ 
จากโอกาสและความรุนแรงของผลกระทบที

่จะเกิดขึ

้ใช้งาน 

้นกับผู

o  หน่วยงานก ากับดูแลการพัฒนาและใช้งานปัญญาประดิษฐ์ ควรให้บุคคลหรือ
่ส าคัญจากระบบปัญญาประดิษฐ์ ได้มีส่วนร่วมใน
่ยงด้วย 

กลุ
่ได้รับผลกระทบที
กระบวนการประเมินความเสี

่มคนที

o  หน่วยงานก ากับดูแลการพัฒนาและใช้งานปัญญาประดิษฐ์ ควรมีการทบทวน
่ในโครงสร้างการก ากับ 
่ยนแปลงโครงสร้างหรือบุคคล 

ประสิทธิภาพการท างานของหน่วยงานและเจ้าหน้าที
ดูแลอย่างสม่
่ส าคัญ 
ที

 าเสมอ และทุกครั

่มีการเปลี

้งที

29 Council of Europe. Guidelines on Artificial Intelligence and Data Protection. Consultative Committee of the Convention for the 
Protection of individuals with regard to Automatic Processing of Personal Data. Jan 25 2019. 

20 | P a g e  

 
 
 
                                                           
Digital Thailand - AI Ethics Guideline 

o  หน่วยงานรัฐ 

่งขึ

▪  ควรมีการวางแผนเพื

่มีความสามารถในการปรับปรุงตนเองได้อย่างต่อเนื

่อก ากับดูแล เฝ้าระวังและจัดการความเสี
่อปัญญาประดิษฐ์มีความฉลาดมากยิ

่ยง 
้นกว่า
ในระยะยาว โดยเฉพาะเมื
ในปัจจุบัน เช่น ปัญญาประดิษฐ์ทั
่วไป (Artificial General Intelligence 
(AGI)) ซุปเปอร์ปัญญาประดิษฐ์ (Artificial Superintelligence) และ
ปัญญาประดิษฐ์ที
่อง 
(Recursive Self-Improving AI)30 
▪  ควรสนับสนุนให้เกิดความร่วมมือเพื
่อพัฒนาโครงสร้างการก ากับดูแล
้งในระดับองค์กร ประเทศ ภูมิภาค 
ปัญญาประดิษฐ์ในแบบบูรณาการ ทั
่ยงการแข่งขัน 
และให้ความร่วมมือกับนานาชาติ ในการหลีกเลี
่ไม่พึงประสงค์ รวมถึงการสร้างอาวุธอัตโนมัติ  
ด้านปัญญาประดิษฐ์ที
จากปัญญาประดิษฐ์ที
่ยนความรู
่ร้ายแรง สนับสนุนให้เกิดการแลกเปลี
และประสบการณ์ในการก ากับดูแล และร่วมกันรับมือกับผลกระทบ
ของปัญญาประดิษฐ์ 

• ความเท่าเทียม หลากหลาย ครอบคลุม และเป็นธรรม (Fairness) 

o  ควรก าหนด ส่งเสริมและสนับสนุนแนวทางปฏิบัติที

่เกี

่ยวข้องกับการประยุกต์ใช้

ปัญญาประดิษฐ์ที

่หลากหลายตามชนิดและสถานการณ์ในการใช้งาน 

่อวิเคราะห์ ประเมินความเสี

o  หน่วยงานก ากับดูแลการพัฒนาและใช้งานปัญญาประดิษฐ์ ควรมีกระบวนการ
่ยง และจัดการปัญหาการเอนเอียงไปสู
้นตอนการวิจัย ออกแบบ พัฒนา และให้บริการ

ควบคุมเพื
ความไม่เป็นธรรมในขั
ปัญญาประดิษฐ์อย่างชัดเจนและโปร่งใส  

o  หน่วยงานรัฐ 

▪  ควรส่งเสริมให้เกิดแพลตฟอร์มเปิดของปัญญาประดิษฐ์เพื

การผูกขาด ท าให้เกิดการแลกเปลี
ปัญญาประดิษฐ์เพื
่องเพื
ต่อเนื

่ยนความรู
่อสร้างสรรค์ ต่อยอดองค์ความรู

่อใช้งานในระดับอุตสาหกรรมได้ 

่ยง
่อหลีกเลี
้ในการพัฒนา
้ และพัฒนาอย่าง

30 Smart Dubai. AI Ethics Principles & Guidelines. Version 1.6. Dec 30 2018. 

21 | P a g e  

 
้
 
่
                                                           
Digital Thailand - AI Ethics Guideline 

▪  ควรสนับสนุนให้เกิดโอกาสในการพัฒนาปัญญาประดิษฐ์ที
่เป็นธรรม ทั

่เท่าเทียมกัน
้งในระดับภูมิภาคและอุตสาหกรรม 

และการแข่งขันที
่แตกต่างกัน 
ที

▪  ควรส่งเสริมและสนับสนุนให้เกิดโอกาสที

การศึกษ า  สินค้า บริการ แ ละ เทคโนโลยีที
ปัญญาประดิษฐ์ 

่เท่าเทียมกัน ในการเข้าถึง
่ยวข้องด้าน
่เกี

่อการเปลี

่มคนท างานเพื

▪  ควรส่งเสริมให้ประชาชนมีทักษะด้านปัญญาประดิษฐ์และสนับสนุน
่เป็นธรรม (Fair Transition)31
กลุ
่ยนผ่านที
หน่วยงานรัฐควรส่งเสริมให้เกิดการวิจัยและพัฒนาเทคนิค 
การวิเคราะห์เพื
่อใช้ตรวจสอบและแก้ไขปัญหาความเอนเอียง แบ่งแยก 
และไม่เป็นธรรมของปัญญาประดิษฐ์ 

• ความน่าเชื

่อถือ (Reliability) 

่อถือของปัญญาประดิษฐ์และชุดข้อมูลอย่างสม่

o  ควรก าหนดนโยบาย หลักเกณฑ์ และกระบวนการในการประเมินคุณภาพของ
ชุดข้อมูลและโมเดลปัญญาประดิษฐ์ ด าเนินการทบทวนและปรับปรุงความ
 าเสมอ โดยน าข้อมูล 
น่าเชื
่อให้ระบบสอดรับกับการ
ผลสะท้อนกลับที
้ใช้งานระบบจริงมาใช้ เพื
้ใช้งานตามระยะเวลา ควรปรับปรุงโมเดลด้วยชุด
เปลี
่ยง
ข้อมูลที
เปลี

่ได้รับจากผู
่ยนแปลงพฤติกรรมของผู

่เป็นปัจจุบัน และควรปรับปรุงโมเดลเมื

่อวัตถุประสงค์และความเสี

่ยนแปลงไป 

o  ควรก าหนดนโยบายและกระบวนการเพื
ผู
้ใช้งาน และด าเนินการทบทวนอย่างสม่
ข้อมูลที
o  หน่วยงานรัฐ 

่จ าเป็น และรับผลสะท้อนจากการให้บริการได้อย่างมีประสิทธิภาพ 

่อทบทวนช่องทางการสื
 าเสมอ เพื

่อสารกับ
่อสนับสนุนการเปิดเผย

▪  ควรสนับสนุนการวิจัย ออกแบบ พัฒนา ให้บริการ และใช้งาน
่อถือ 

ปัญญาประดิษฐ์ที

่มีความน่าเชื

31 OECD Legal Instruments. Recommendation of the Council on Artificial Intelligence. May 22 2019. จาก 
https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449. 

22 | P a g e  

 
 
                                                           
Digital Thailand - AI Ethics Guideline 

▪  ควรก าหนดนโยบายที
ที
่มีความน่าเชื
ของปัญญาประดิษฐ์เพื

่ช่วยเปิดโอกาสให้เกิดการใช้งานปัญญาประดิษฐ์
่อถือ

่อถือ และพัฒนาแนวทางการประเมินความน่าเชื
้ให้บริการ 
่ยนได้ตามลักษณะ

่อใช้ตรวจประเมินผู

้พัฒนาและผู

❖ แนวทางการประเมินควรสามารถปรับเปลี

การน าปัญญาประดิษฐ์ไปใช้งาน 

❖ แนวทางการประเมินควรได้รับการพัฒนาขึ
้งภาครัฐและเอกชน 

่มีส่วนได้เสียทั
้ที

ของผู

้นด้วยความร่วมมือ

▪  ควรประเมินและตรวจสอบคุณภาพผู
ข้อมูลจากผลลัพธ์ของระบบ เพื
มนุษย์อย่างเข้มงวด 

้ให้บริการปัญญาประดิษฐ์ที
่ส าคัญที

่ใช้
่ยวข้องกับ

่เกี

่อการตัดสินใจที

2)  ผู

้วิจัย ผู

้ออกแบบ ผู

้พัฒนา และผู

้ให้บริการ 

•  ความสามารถในการแข่งขันและการพัฒนาอย่างยั

่งยืน (Competitiveness 

and Sustainability Development) 
o  มีความรู
้ความเข้าใจที

่จ าเป็นเกี

่ยวกับปัญญาประดิษฐ์ในส่วนที
อย่างเพียงพอ ทราบถึงประโยชน์และผลกระทบของระบบ เพื
จากปัญญาประดิษฐ์ให้แก่มนุษย์ สังคม เศรษฐกิจ และสิ
และลดความเสี

้นจากปัญญาประดิษฐ์ 

่ยงต่าง ๆ ที

่อาจเกิดขึ

่ตนเองเกี
่ยวข้อง
่อสร้างประโยชน์
่งยืน 

่งแวดล้อมอย่างยั

o  ควรออกแบบ พัฒนาและน าปัญญาประดิษฐ์ไปใช้งาน โดยค านึงถึงประโยชน์ 

่จะเกิดขึ
ที

้นกับมนุษย์โดยรวม ผู

่มีส่วนได้เสีย และสิ
้ที

่งแวดล้อมอย่างยั

o  ควรออกแบบ และพัฒนาให้ปัญญาประดิษฐ์สามารถปรับเปลี

่งยืน 
่ยนการท างานได้

ตามสภาพแวดล้อมต่าง ๆ เพื

่อเอื

้อประโยชน์ให้แก่มนุษย์อย่างสร้างสรรค์ 

23 | P a g e  

 
 
 
 
 
Digital Thailand - AI Ethics Guideline 

• ความสอดคล้องกับกฎหมาย จริยธรรม และมาตรฐานสากล (Laws Ethics 

and International Standards) 
o  ควรมีมาตรการในประเมิน ลดหรือหลีกเลี

่ยงความเสี

่ยงด้านกฎหมาย จริยธรรม 
่งแวดล้อม 

การละเมิดสิทธิเสรีภาพ สิทธิมนุษยชน ผลกระทบต่อสังคมและสิ
และควรมีมาตราเยียวยาผู

่ได้รับผลกระทบจากปัญญาประดิษฐ์ 
้ที
o  ควรใช้หลักการออกแบบและน าปัญญาประดิษฐ์ไปใช้งานที
้เชี

่ค านึงถึงจริยธรรม
่จะน าปัญญาประดิษฐ์ไปใช้งาน
้นตอนการออกแบบ พัฒนา  

ในการสร้างระบบ โดยให้ผู
่ยวชาญในแขนงที
รวมถึงสถาบันการศึกษา มีส่วนร่วมในขั
และให้บริการ 
้ให้บริการปัญญาประดิษฐ์ควรก าหนดรายละเอียดหลักการจริยธรรมไว้ใน
กระบวนการปฏิบัติงาน หรือใช้เป็นข้อก าหนดหนึ
่งในผลิตภัณฑ์และบริการ 
และแจ้งให้ผู

้ใช้งานได้รับทราบ 

o  ผู

o  ควรท าการประเมินจริยธรรมในการวิจัย ออกแบบ พัฒนา ให้บริการ  
้มีส่วนได้เสีย

และใช้งานปัญญาประดิษฐ์ และเผยแพร่สรุปผลการประเมินให้ผู
ได้รับทราบ 

o  ควรมีการประเมินความเสี

่ยงของผลกระทบจากการวิจัย ออกแบบ พัฒนา 

ให้บริการ และใช้งานเทียบกับหลักการทางจริยธรรม 

o  ควรใช้หลักการออกแบบและน าไปใช้งานที

่ให้มนุษย์เป็นศูนย์กลาง (Human 

Centric) และคงไว้ซึ

่งสิทธิ

์ให้มนุษย์เป็นผู

้เลือกตัดสินใจ 

▪  ควรออกแบบปัญญาประดิษฐ์ให้สามารถส่งต่อการด าเนินการและ 

การตัดสินใจไปยังมนุษย์ ได้ 

▪  ควรออกแบบปัญญาประดิษฐ์ให้มนุษย์สามารถเข้าแทรกแซง
่งอิสรภาพของ
กระบวนการตัดสินใจของปัญญาประดิษฐ์ และคงไว้ซึ
่เกิดจากค าแนะน าของ
มนุษย์ในการเลือกตัดสินใจที
ปัญญาประดิษฐ์ โดยมีกลไกในการอนุญาตให้มนุษย์สามารถเข้า 
แทรกแซงปัญญาประดิษฐ์ อาทิ 

่จะไม่ใช้ผลลัพธ์ที

24 | P a g e  

 
Digital Thailand - AI Ethics Guideline 

❖ ความสามารถที

่มนุษย์จะเข้าแทรกแซงในทุก ๆ ขั

้นตอนการ

ตัดสินใจของปัญญาประดิษฐ์ 

❖ ความสามารถที

่มนุษย์จะเข้าแทรกแซงในระหว่างขั

้นตอนการ
ออกแบบปัญญา ประดิษฐ์ และเฝ้าระวังการปฏิบัติงานของ
ระบบ  

❖ ความสามารถของมนุษย์ในการตรวจสอบกิจกรรมทั

้งหมดของ
ปัญญาประดิษฐ์ และสามารถตัดสินใจเลือกหรือไม่เลือกใช้งาน
ระบบในสถานะการณ์ต่าง ๆ รวมถึงความสามารถในการปรับ
ระดับในการตัดสินใจระหว่างใช้งาน หรือความสามารถในการ
ครอบง าการตัดสินใจของปัญญาประดิษฐ์ 

• ความโปร่งใสและภาระความรับผิดชอบ (Transparency and Accountability) 
o  ควรเปิดเผยวัตถุประสงค์ เหตุผลการตัดสินใจของปัญญาประดิษฐ์ ชุดข้อมูล 
่ใช้งาน กระบวนการท างาน และความ
ความสามารถ ข้อจ ากัด อัลกอริทึมที
่อถือของปัญญาประดิษฐ์อย่างโปร่งใส โดยไม่ละเมิดความเป็นส่วนตัวและ
น่าเชื
้ง
่อาจได้รับผลกระทบทั
้ที
่สามารถอธิบายให้ผู
ทรัพย์สินทางปัญญา ในลักษณะที
่แตกต่างกัน
ทางตรงและทางอ้อมให้เข้าใจได้ โดยค านึงถึงความรู
้ความเข้าใจที
้ใช้งาน
่อให้ผู
่หลากหลาย เพื
้ใช้งานและสถานการณ์ในการน าไปใช้งานที
ของผู
สามารถตั
้งข้อสงสัยต่อการท างานของปัญญาประดิษฐ์ ตรวจพบ และตระหนัก
ถึงความเอนเอียง ความผิดพลาด และผลลัพธ์ที

้งใจได้โดยง่าย  
่มีข้อจ ากัดในการให้ค าอธิบายอัลกอริทึมปัญญาประดิษฐ์ เนื

o  ในกรณีที

่ไม่ได้ตั

่มีเจ้าของโดยเฉพาะ (Proprietary data) เกี
่นคง ปลอดภัย ผู

่องมาจาก
่ยวข้องกับทรัพย์สิน
้พัฒนาควร
 า (Repeatability) 
่งเป็นความสามารถในการสร้าง ผลลัพธ์เดิม 
่นให้กับระบบ โดยควร
่อมั

้วิจัย ผู
่ความสามารถในการท าซ้

้ออกแบบ และผู

่อสร้างความเชื

เป็นข้อมูลที
ทางปัญญา และความมั
บันทึกและให้ข้อมูลที
ของปัญญาประดิษฐ์ ซึ
กับสถานการณ์ในลักษณะเดิมได้ เพื
ด าเนินการดังต่อไปนี

่บ่งบอกที

้ 

25 | P a g e  

 
 
Digital Thailand - AI Ethics Guideline 

▪  ท าการประเมินและทดสอบความสามารถในการท าซ้

 าของ

ปัญญาประดิษฐ์ 

 าได้ 

▪  ท าการประเมินวิธีการในการระบุและจัดการข้อยกเว้น (Exceptions) 
่งๆ ไม่สามารถท าซ้

่การตัดสินใจหนึ
ในกรณีที
่อาจได้รับผลกระทบจากปัญญาประดิษฐ์ ควรได้รับการแจ้ง
้ที
่มีส่วนได้เสียที
่ยวกับเหตุผลในการ
์ในการขอข้อมูลเกี
เตือนและรับทราบอย่างเพียงพอ มีสิทธิ
้น และ
ใช้งานปัญญาประดิษฐ์กับตนเอง รวมถึงผลกระทบของเหตุผลเหล่านั
้ง
้นตอนของการออกแบบและพัฒนาปัญญาประดิษฐ์ทั
ควรมีส่วนร่วมในขั
ทางตรงและทางอ้อมตลอดวัฏจักรชีวิตของระบบ (Stakeholder 
Participation) 
้ใช้งานควรได้รับแจ้งว่าก าลังสื
่อสารกับปัญญาประดิษฐ์ซึ
และรับทราบว่าผลลัพธ์ของการตัดสินใจเกิดจากปัญญาประดิษฐ์ 

่งมิใช่มนุษย์  

o  ผู

o  ผู

o  ควรมีความตระหนักรู

้ในเรื

่องภาระความรับผิดชอบ (Accountability) โดยมี
่ของ

ส่วนร่วมรับผิดชอบต่อการผลกระทบจากปัญญาประดิษฐ์ ตามภาระหน้าที
ตนเอง 

o  ควรออกแบบให้ปัญญาประดิษฐ์มีความสามารถในการสืบย้อนกลับ 
(Traceability) ได้จาก Audit log สามารถเฝ้าระวัง ตรวจสอบความผิดปกติ
่มา
และวินิจฉัยปัญหาความล้มเหลวได้ (Diagnosability) ได้ ทั
และวิธีการเก็บรวบรวมข้อมูล ชุดข้อมูล อัลกอริทึม และกระบวนการตัดสินใจ 
้ใช้งานได้  
่สามารถสร้างผลกระทบที
ของปัญญาประดิษฐ์ที
โดยแนวทางปฏิบัติเพื

่อสร้างความสามารถในการสืบย้อนกลับ ประกอบด้วย 

้งในส่วนของที

่ส าคัญกับผู

▪  การบันทึกข้อมูลและกิจกรรมที

้นระหว่างการวิจัย ออกแบบ 
่เกิดขึ
พัฒนา และการให้บริการ ตามล าดับเวลาของเหตุการณ์ (Audit trail) 
❖ ข้อมูลชุดการสอนปัญญาประดิษฐ์ วิธีการในการเก็บรวบรวม
่อนย้ายข้อมูล ผลการตรวจวัดความ

และปรับแก้ การเคลื
แม่นย าของปัญญาประดิษฐ์ตลอดช่วงเวลาที
่เลือกใช้ 
่ใช้ออกแบบและอัลกอริทึมที

❖ โมเดลที

่ด าเนินการ 

26 | P a g e  

 
Digital Thailand - AI Ethics Guideline 

่ยนแปลงโค๊ดโปรแกรม (Code) และผู

่ท าการ
้ที

่ไหลเข้าระบบทั

้งหมดในช่วงเวลาที

่มีการใช้

่ยนแปลง 

❖ การเปลี
เปลี
▪  การบันทึกกระแสข้อมูลที
งานปัญญาประดิษฐ์ 
▪  มีการจัดเก็บข้อมูลเพื
่อหลีกเลี

่อการสืบย้อนในหน่วยจัดเก็บข้อมูลที

่ยงการถูกลดทอนคุณภาพ หรือถูกเปลี

เพื
และควรจัดเก็บไว้ตามระยะเวลาที
ข้อก าหนดในมาตรฐานอุตสาหกรรมที
่เกิดขึ

▪  การบันทึกข้อมูลและกิจกรรมที

่เหมาะสม
่ยนแปลงแก้ไข  
่สอดคล้องกับกฎหมายหรือ

่น าปัญญาประดิษฐ์ไปใช้งาน 
้นระหว่างการออกแบบ พัฒนา 

และการให้บริการ ตามล าดับเวลาของเหตุการณ์ (Audit trail) 

o  ควรมีกระบวนการทบทวนข้อมูล กิจกรรม และกระบวนการที

้นระหว่าง
่เกิดขึ
การวิจัย  ออกแบบ  พัฒนา  และการให้บริการ  หลังจากผู
้ใช้ง าน 
น าปัญญาประดิษฐ์ไปใช้งานเรียบร้อยแล้ว และหากพบว่าข้อมูล กิจกรรม  
และกระบวนการที
้นระหว่างการวิจัย ออกแบบ พัฒนา และการให้บริการ
ปัญญาประดิษฐ์มีข้อผิดพลาด ควรจัดให้มีกระบวนการพิจารณาแก้ไขปรับปรุง
ในล าดับถัดไป 

่เกิดขึ

• ความมั

่นคงปลอดภัยและความเป็นส่วนตัว (Security and Privacy) 
o  ควรออกแบบ พัฒนาและให้บริการปัญญาประดิษฐ์ ให้มีการป้องกันความเสี

โดยสร้างให้ปัญญาประดิษฐ์มีกลไกการรักษาความมั
ระบบจากภัยคุกคามและการใช้งานที
่ส าคัญ ข้อมูลส่วนบุคคล จริยธรรม ชีวิตและสิ
ที

่ไม่พึงประสงค์ ที

่งแวดล้อม  

่ยง 
่นคงปลอดภัยและป้องกัน
่อาจกระทบต่อข้อมูล 

o  ปัญญาประดิษฐ์ที

่ประมวลผลข้อมูลส่วนตัวควรใช้หลักการที

่สอดคล้องกับ
กฎหมาย (Lawfulness) ความเป็นธรรม (Fairness) มีวัตถุประสงค์ที
่เฉพาะ 
(Purpose S p e c i fi c a t i o n )   มี ก า ร ป ร ะ ม ว ล ผ ล ต า ม วั ต ถุ ป ร ะ ส ง ค์  
่ค านึงถึงความ
(Proportionality of data processing) และการออกแบบที

27 | P a g e  

 
 
Digital Thailand - AI Ethics Guideline 

เ ป็ น ส่ ว น ตั ว โ ด ย ป ริ ย า ย  (Privacy-by-design and by-default)32  แ ละ
สอดคล้องกับกฎหมาย พรบ. คุ

้มครองข้อมูลส่วนบุคคล พ.ศ. 2562 

o  ควรออกแบบและพัฒนาปัญญาประดิษฐ์ให้มีกลไกการป้องกันความครบถ้วน
ถูกต้อง (Integrity) ของข้อมูลชุดการสอนระบบ โดยสามารถแยกและก าจัด
ข้อมูลที

่ไม่พึงประสงค์ออกจากข้อมูลปกติแต่มีจ านวนน้อยได้ 

ส่วนตัวที
ระหว่างขั

o  ควรประเมินคุณภาพ ลักษณะตามธรรมชาติ แหล่งที
่ถูกน ามาใช้ โดยลดการใช้ข้อมูลส่วนตัวที
้นตอนการสอนระบบ 
้นตอนการพัฒนาและขั
o  ควรด าเนินการกับข้อมูลส่วนตัวที
่เกี
้ใช้งานทราบล่วงหน้าถึงข้อมูลที

▪  แจ้งให้ผู

่ยวข้องอย่างเคารพและถูกต้อง ดังนี

้ 

่จะถูกเก็บรวบรวมและ 

่มา และจ านวนข้อมูล
 าซ้อน
่ไม่จ าเป็นหรือซ้

การน าไปใช้ โดยต้องได้รับการยินยอมจากเจ้าของข้อมูลเสียก่อน 

▪  เก็บรวบรวมข้อมูลส่วนตัวเท่าที

่จ าเป็น จ ากัดการเข้าถึงและจัดเก็บไว้ 

ตามระยะเวลาเท่าที

่จ าเป็น 

▪  มีระบบป้องกันข้อมูลส่วนตัว อาทิ ระบบยืนยันตัวตน ระบบสนับสนุน
้งหมด 
้ใช้งานในการค้นหา ข้อมูลส่วนตัว และการลบข้อมูลส่วนตัวทั
ผู
่สามารถใช้งานได้โดยง่าย 
ที

▪  มีกระบวนการทบทวนความสอดคล้องของปัญญาประดิษฐ์กับกฎหมาย

คุ

้มครองข้อมูลส่วนบุคคล 
o  ควรดูแลสภาพแวดล้อมของการปฏิบัติงานที
้งในแบบที
่ส าคัญต่อมนุษย์และสิ
่งมีภาระกิจหรือให้บริการโครงสร้างพื

ปลอดภัย เพื
่มีผลกระทบเชิงลบต่อข้อมูลที
ที
o  หน่วยงานของรัฐและเอกชน ซึ

่อป้องกันภัยคุกคามทั

่เกี
่ไม่ได้ตั

่ยวข้องให้มีความมั

่งแวดล้อม 

้งใจและไม่ประสงค์ดี  

้นฐาน

่นคง

ส าคัญสารสนเทศ ตาม พรบ. การรักษาความมั
พ.ศ. 2562 ควรรักษาความมั
ปัญญาประดิษฐ์ที

่นคงปลอดภัยทางไซเบอร์  
่นคงปลอดภัยทางไซเบอร์กับระบบ
้ 

่ให้บริการสอดคล้องกับกฎหมายฉบับนี

32 Council of Europe. Guidelines on Artificial Intelligence and Data Protection. Consultative Committee of the Convention for the 
Protection of individuals with regard to Automatic Processing of Personal Data. Jan 25 2019. 

28 | P a g e  

 
                                                           
Digital Thailand - AI Ethics Guideline 

o  ควรออกแบบและพัฒนาปัญญาประดิษฐ์ ให้มีกลไกในการตรวจสอบ เฝ้าระวัง 
และแจ้งเตือนถึงภัยคุกคาม รวมถึงความสามารถในการติดตาม แก้ไขปัญหา 
่สภาวะปกติได้ภายหลังจากการถูกโจมตีโดยภัยคุกคาม 
และกลับคืนสู
(Resilience to attack) 

o  ผู

่อให้มั

่นใจได้ว่าสิทธิ

้ใช้งานจะไม่ถูกละเมิด รวมถึงไม่สร้างผลกระทบต่อชีวิตและสิ

o  ควรออกแบบและพัฒนาปัญญาประดิษฐ์ ให้มีความสามารถในการ 
้คืนระบบจากปัญหาต่าง ๆ (Fallback plan) โดยมีกลไก 
์และประโยชน์ 
่งแวดล้อม

ใช้แผนส ารองเพื
่อกู
ในการเพิกถอนข้อมูลและบริการ เพื
ของผู
ในระหว่างการด าเนินการ 
่จ าเป็นและความสามารถในการใช้
้ที
้ให้บริการปัญญาประดิษฐ์ควรมีความรู
่ยงต่าง ๆ 
่ยงและลดความเสี
่อหลีกเลี
่ได้รับการออกแบบไว้ เพื
งานระบบตามที
ที
่อาจเกิดขึ
o  ผู
้วิจัย ผู
การวิจัย ออกแบบ และพัฒนาปัญญาประดิษฐ์อย่างสม่
ความสามารถในการรักษาความมั
่เกิดขึ
จากภัยคุกคามที
่มีความเสี
้มีส่วนได้เสียที
การแจ้งเตือน และควรมีส่วนร่วมในขั
การให้บริการปัญญาประดิษฐ์ด้วย 

้และทักษะ
่อเพิ
่ม
่ยง
่นคงปลอดภัยของระบบ และลดความเสี

่ยงจะได้รับผลกระทบจากปัญญาประดิษฐ์ ควรได้รับ
้นตอนของการออกแบบ พัฒนา  

้พัฒนาปัญญาประดิษฐ์ ควรพัฒนาความรู

้นจากการให้บริการ 

้ออกแบบ และผู

 าเสมอ เพื

้นใหม่ 

o  ผู

o  ปัญญาประดิษฐ์ที

่อาจส่งผลกระทบกับมนุษย์ ควรให้ผู

น าปัญญาประดิษฐ์ไปใช้งานมีส่วนร่วมในขั
และให้บริการ 

้เชี

่ยวชาญในแขนงที

่จะ
้นตอนการออกแบบ พัฒนา  

• ความเท่าเทียม หลากหลาย ครอบคลุม และเป็นธรรม (Fairness) 

o  ควรวิจัย ออกแบบ และพัฒนาปัญญาประดิษฐ์ โดยเข้าใจถึงความต้องการ 
่มคน
้มีภาวะทุพพลภาพต่าง ๆ  

้ใช้งานที
และความคาดหวังของผู
ส่วนน้อยและผู
้ด้อยโอกาส อาทิ ผู
และเคารพต่อความสามารถและศักยภาพของมนุษย์ 

่มีความหลากหลายในสังคม ค านึงถึงกลุ

้พิการและผู

29 | P a g e  

 
 
Digital Thailand - AI Ethics Guideline 

้ออกแบบ ผู

้วิจัย ผู
่หลากหลาย และควรได้รับค าแนะน าจากผู

้พัฒนา และผู

้ทดสอบปัญญาประดิษฐ์ ควรมี
่ยวชาญในแขนง
่ยงในการเกิดความ 

้เชี

่อช่วยลดความเสี

่มผู
้นหลังที

o  สมาชิกในกลุ
ประวัติพื
่จะน าปัญญาประดิษฐ์ไปใช้งาน เพื
ที
ไม่ธรรมขึ
่มีส่วนได้เสียที
้ที
ปัญญาประดิษฐ์ ควรมีส่วนร่วมในขั

้นกับระบบ 

o  ผู

่อาจได้รับผลกระทบจากความเอนเอียงและไม่ธรรมของ

้นตอนการออกแบบและพัฒนาระบบ 

o  ควรตรวจสอบและแก้ไขปัญญาประดิษฐ์ที

่ไม่ได้ออกแบบไว้  (Non-operational bias) 33 ซึ
ที
ปัญญาประดิษฐ์เข้าไปเกี
่เกี
และการตั

่ยวข้องกับกลุ
่ยวข้องกับผู

้ใช้งานปัญญาประดิษฐ์ที

้งสมมติฐานที

่มคนและกระบวนการที

่ให้ผลลัพธ์การตัดสินใจที
่งอาจเกิดขึ

่เอนเอียง 
้นจากที
่แตกต่างกัน  

o  ควรออกแบบปัญญาประดิษฐ์ให้มีทางเลือกที

่หลากหลายให้กับผู

่ไม่ถูกต้อง เป็นต้น 
้ใช้งานในการ

ด าเนินการเพื

่อบรรลุถึงเป้าหมาย 

o  ควรเก็บรวบรวมข้อมูลเพื

่อน ามาใช้กับปัญญาประดิษฐ์จากหลากหลาย

แหล่งข้อมูลที
o  ชุดข้อมูลที

่มีความน่าเชื

่อถือ เพื

่อลดความเอนเอียงของข้อมูล 

ใช้เป็นตัวแทนของประชากรที
o  ชุดข้อมูลและอัลกอริทึมที

่น ามาใช้กับปัญญาประดิษฐ์ ควรตรวจสอบให้แน่ใจว่าสามารถ 
่ได้รับผลกระทบทั
้งหมด (Representativeness) 
่มีลักษณะเอนเอียงไปในทางแบ่งแยกและ 
้นตอนการเก็บข้อมูล 
่ไม่สามารถก าจัด 
้งหมด ควรมีกลไก 

ไม่เป็นธรรม ควรได้รับการก าจัดออกไปในขั
และการคัดเลือกอัลกอริทึมตามล าดับ ทั
ความเอนเอียงของชุดข้อมูลและอัลกอริทึมได้ทั
ในการตรวจสอบความเอนเอียงและให้บริการปัญญาประดิษฐ์อย่างปลอดภัย 
่อให้
้นได้ในแต่ละ 

o  ควรใช้ชุดข้อมูลในการสอน ทดสอบ และพิสูจน์โมเดลที
สามารถตรวจสอบพบความเอนเอียงของผลลัพธ์ที
ชุดข้อมูล 

่แตกต่างกัน เพื

่อาจเกิดขึ

้ในกรณีที

้งนี

o  ควรพัฒนาปัญญาประดิษฐ์ให้สอดคล้องกับมาตรฐานสากลหรือแนวทางด้าน
่ยอมรับ อาทิ ISO 40500:2012 (W3C 
่เป็นที

ความสามารถในการเข้าถึงระบบที

33 Smart Dubai. AI Ethics Principles & Guidelines. Version 1.6. Dec 30 2018. 

30 | P a g e  

 
่
                                                           
Digital Thailand - AI Ethics Guideline 

Web Content Accessibility Guidelines: (WCAG) 2.0)34 และ W3C Web 
Content Accessibility Guidelines (WCAG) เวอร์ชัน 2.135 

o  ผู

o  ควรใช้เครื

่องมือในการตรวจสอบความเอนอียงของปัญญาประดิษฐ์  
่อช่วยลดความไม่เป็นธรรมในระบบ 

(Bias Detection Tools) เพื
้พัฒนาปัญญาประดิษฐ์ควรทดสอบเพื
ผลลัพธ์ตามที
โดยเฉพาะเมื

่อให้แน่ใจว่า ปัญญาประดิษฐ์สามารถให้
่ไม่เคยเห็นในอดีต 

่ออกแบบไว้ได้เป็นอย่างดีเมื
่อใช้กับการประเมินประชากรที

่อพบกับข้อมูลที
่ไม่ได้อยู
้มีภาวะทุพพลภาพได้ร่วมทดสอบวัตถุประสงค์ กระบวนการ
่ได้จากปัญญาประดิษฐ์ ว่าสามารถ
้พิการ
้ใช้งานที

่ในข้อมูลชุดการสอน 

่ส าคัญของผู

่เป็นผู

o  ให้ผู

้พิการหรือผู

o  ผู

้มีภาวะทุพพลภาพได้ 

ท างาน กระบวนการตัดสินใจและผลลัพธ์ที
ตอบสนองความต้องการและความคาดหวังที
หรือผู
้พัฒนาและผู
ด้านการจัดอบรม เครื
่อให้ผู
ปัญญาประดิษฐ์ เพื
o  การพัฒนา และให้บริการปัญญาประดิษฐ์ควรตั

่องมืออุปกรณ์ที
้ใช้งานสามารถเข้าถึงได้โดยง่าย 
้งอยู

่เกี

้ให้บริการปัญญาประดิษฐ์ควรมีการเตรียมความพร้อม 
่ยวข้อง และช่องทางเข้าใช้งาน

้นฐานของความ 
เป็นธรรมทางสังคม ให้เกิดความเท่าเทียมกันในการเข้าถึงสินค้า บริการ  
่ยวข้อง โดยไม่จ ากัดอายุ เพศ ลัทธิชนชาติ ความสามารถ  
และเทคโนโลยีที
และคุณสมบัติ 

่บนพื

่เกี

34 ISO/IEC 40500:2012 (W3C), Information technology – W3C Web Content Accessibility Guidelines (WCAG) 2.0. Oct 2012. 
35 W3C. Web Content Accessibility Guidelines (WCAG) 2.1. Jun 5 2018. ดูได้จาก https://www.w3.org/TR/WCAG21/. 

31 | P a g e  

 
 
 
                                                           
Digital Thailand - AI Ethics Guideline 

• ความน่าเชื

่อถือ (Reliability) 

o  ควรมีการวางแผนวิธีการวิจัย วิธีการออกแบบ วิธีการพัฒนา และวิธีการใช้งาน

ปัญญาประดิษฐ์อย่างเป็นระบบและครบถ้วน 

o  ควรทราบและมีความเข้าใจถึงปัจจัยที

่ส่งผลกระทบกับคุณภาพของชุดข้อมูล 
่ใช้ในปัญญาประดิษฐ์ อาทิ ความแม่นย า (Accuracy) ความสมบูรณ์ 
ที
่อถือ (Veracity) ความเป็นปัจจุบัน (Update) 
(Completness) ความน่าเชื
ความเกี
่ยวข้องของข้อมูล (Relevance) ความครบถ้วนถูกต้อง (Integrity) 
ความสามารถในการน าไปใช้ (Usability) และการถูกแทรกแซงโดยมนุษย์ 
(Human Intervention) เป็นต้น 

o  ควรออกแบบและพัฒนาปัญญาประดิษฐ์ให้มีความสมบูรณ์ แข็งแกร่ง  

และน่าเชื

่อถือ  

▪  มี ความแม่ นย  า  (Accuracy) ในการตั ดสิ นใจ การคาดการณ์   
้นฐานของข้อมูลและโมเดล 

และให้ค าแนะน าบนพื

▪  สร้างผลลัพธ์ที

่สามารถเชื

่อถือได้และสร้างใหม่ได้เมื

่อต้องการ 

(Reliability and Reproducibility)  

▪  มีความเป็นมิตรต่อการผู
o  ควรทราบถึงแหล่งก าเนิดของข้อมูลที

้ใช้งาน (Usability) 

่จะน าใช้ในโมเดล วิธีการรวบรวมข้อมูล 
่ยนข้อมูล การปฏิสัมพันธ์
่อให้ทราบถึงคุณภาพของข้อมูล 

่อนย้ายของข้อมูล การปรับเปลี

การเก็บรักษา การเคลื
กับข้อมูลอื
่น ามาใช้ รวมถึงข้อผิดพลาดที
ที
o  ควรพิจารณาก่อนน าข้อมูลที

่น จนถึงการน าเสนอข้อมูล เพื
่ส าคัญต่าง ๆ 
่ด าเนินการเก็บรวบรวมไปใช้ ว่าบริบทที

้นตอนการเก็บรวบรวม ข้อมูลเหมาะสมกับลักษณะที
ขั
่ตั
ตามที

้งใจไว้จริง 
o  ควรรับค าปรึกษาจากผู

่ยวชาญในแขนงที

้เชี
่ยวข้องกับข้อมูลที

่ยวข้องในการพัฒนา
่มีความอ่อนไหว (Sensitive Data) อาทิ 
ปัญญาประดิษฐ์ที
ข้อมูลทางการแพทย์ ข้อมูลพนักงาน ข้อมูลทางการเงิน และการบังคับใช้
กฎหมาย เป็นต้น 

่เกี

่เกี

่ใช้ใน
่จะน าไปใช้งาน 

32 | P a g e  

 
Digital Thailand - AI Ethics Guideline 

่อนไขและสภาวะแวดล้อมจริง เพื

o  ควรด าเนินการทดสอบโมเดลปัญญาประดิษฐ์ให้สอดคล้องกับความเป็นพลวัต
ของเงื
้ใช้งาน 
และสภาพแวดล้อมโดยรอบ และควรเฝ้าระวัง ทบทวน และปรับปรุงโมเดล
อย่างเหมาะสม 

่อความปลอดภัยของผู

o  ควรมีแนวทางในการพิสูจน์ว่าปัญญาประดิษฐ์ด าเนินการตามที

่ได้ออกแบบไว้

o  ผู

o  ผู

่อนไขการปฏิบัติงานจริง 

ภายใต้เงื
้ให้บริการปัญญาประดิษฐ์ควรมีกระบวนการเฝ้าระวัง บันทึกและตรวจสอบ
การท างานของปัญญาประดิษฐ์ เพื
่อช่วยในการตรวจสอบและท าความเข้าใจ
ผลลัพธ์ทางประสิทธิภาพของปัญญาประดิษฐ์ 
้ให้บริการปัญญาประดิษฐ์ควรมีช่องทางการรับผลสะท้อนกลับ (Feedback) 
่เกิดจากระบบ (Decision 
รวมถึงช่องทางการขอให้ทบทวนการตัดสินใจที
Review) ที
้ใช้งานสามารถแจ้งปัญหาของ
ปัญญาประดิษฐ์ที

่อให้ผู
่ตรวจสอบพบค าร้องและน าแนะน าต่าง ๆ ได้ 

่ง่ายและรวดเร็ว  เพื

33 | P a g e  

 
 
3)  ผู

้ใช้งาน 

Digital Thailand - AI Ethics Guideline 

•  ควรศึกษา อบรมเพื

่อให้มีความรู

้ 
่ยวกับประโยชน์และตระหนักรู
่วไปเกี
้ทั
ถึงผลกระทบของการใช้งานปัญญาประดิษฐ์ รวมถึงทักษะในการใช้งานและท างาน
ร่วมกับปัญญาประดิษฐ์อย่างถูกต้อง 

•  ควรติดตามข่าวสารที

่เกี
ทราบถึงองค์ความรู
และสามารถรับมือกับภัยคุกคามต่างๆ 

่ยวข้องกับเทคโนโลยีปัญญาประดิษฐ์อย่างสม่
่อให้
้ใหม่ๆ   ส าหรับปรับใช้ประโยชน์ในชีวิตประจ าวัน  

 าเสมอ เพื

•  ควรตรวจสอบความน่าเชื

่อถือของผลิตภัณฑ์และบริการปัญญาประดิษฐ์ก่อน 
รับบริการโดยดูจากรายละเอียดการออกแบบและหลักการท างานของ
้ให้บริการแสดง ผลประเมิน 
้พัฒนา และผู
่ผู
ปัญญาประดิษฐ์ที
ความน่าเชื
่ได้รับ
่อถือของระบบและใบรับรองผลิตภัณฑ์และบริการจากสถาบันที
การยอมรับ และผลสะท้อนกลับจากผู

่เคยรับบริการอื
้ที

้ออกแบบ ผู

่น เป็นต้น 

•  ผู

้ใช้งานควรร้องขอรายละเอียดหลักการจริยธรรมที
้ให้บริการ 
ปัญญาประดิษฐ์จากผู

่ใช้ในผลิตภัณฑ์และบริการ

•  ผู

้ใช้งานควรทราบถึงภาระความรับผิดชอบ (Accountability) ของตนเองในการ 
ใช้งานผลิตภัณฑ์และบริการปัญญาประดิษฐ์ 

•  ผู

่อาจได้รับผลกระทบจากปัญญาประดิษฐ์ ควรร้องขอข้อมูลเกี
้ที
ในการใช้งานปัญญาประดิษฐ์กับตนเอง รวมถึงผลกระทบของเหตุผลเหล่านั
และควรมีส่วนร่วมในกระบวนการออกแบบ พัฒนา และประเมินความเสี
ของระบบปัญญาประดิษฐ์ 

่ยวกับเหตุผล 
้น  
่ยง 

•  ผู
้ให้บริการ 
้ใช้งานควรแจ้งผลการใช้งานปัญญาประดิษฐ์สะท้อนกลับให้กับผู
่อการปรับปรุง แก้ไข และพัฒนาให้สอดคล้องกับความวัตถุประสงค์  
เพื
่ยนแปลงตามระยะเวลา 
และพฤติกรรมการใช้งานที

่เปลี

•  ควรร้องขอค าอธิบายที
้วิจัย ผู

จากผู

้ออกแบบ และผู

่ง่ายแก่การเข้าใจและสอดคล้องกับบริบทที

่ยวข้อง 
่ยวกับรายละเอียดการออกแบบ 

่เกี

้ให้บริการ เกี

34 | P a g e  

 
Digital Thailand - AI Ethics Guideline 

และหลักการท างานของปัญญาประดิษฐ์ เพื
ตระหนักถึงความเอนเอียง ความผิดพลาด การท างานของปัญญาประดิษฐ์ได้ 

่อให้สามารถตั

้งข้อสงสัย ตรวจพบ 

•  หากมีการน าข้อมูลส่วนตัวไปใช้เพื

้ใช้งานมีสิทธิตามกฎหมาย พรบ. คุ

่อการวิจัย ออกแบบ พัฒนา และให้บริการ
้มครองข้อมูลส่วนบุคคล  

ปัญญาประดิษฐ์ ผู
ปี 2562 อาทิเช่น 

▪  การขอเข้าถึงและรับส าเนาข้อมูลส่วนบุคคลที

่เกี

่ยวกับตนเอง และขอให้

เปิดเผยถึงการได้มาซึ

่งข้อมูลดังกล่าว 

▪  มีสิทธิในการถอนความยินยอมและคัดค้านการเก็บรวบรวม ใช้ หรือ

เปิดเผยข้อมูล 
▪  มีสิทธิขอให้ผู

้ควบคุมข้อมูลส่วนบุคคลของผู

้วิจัย ผู

และผู

้ให้บริการ ลบหรือท าลาย และระงับการใช้งานข้อมูลชั

้พัฒนา  

้ออกแบบ ผู
่วคราว 

▪  มีสิทธิท าให้ข้อมูลส่วนบุคคลของตนเองถูกต้องเป็นปัจจุบัน สมบูรณ์  

ไม่ก่อให้เกิดความเข้าใจผิด 

35 | P a g e  

 
 
 
Digital Thailand - AI Ethics Guideline 

อภิธำนศัพท์ (Glossary) 

ปัญญาประดิษฐ์ หมายถึง ศาสตร์ที
ทางด้านวิทยาศาสตร์และวิศวกรรมศาสตร์ มาพัฒนาให้เครื
สามารถคิด ค านวณ วิเคราะห์ เรียนรู
พัฒนาและปรับปรุงกระบวนการท างานเพื

่รวบรวมองค์ความรู

้ในหลายสาขาวิชา โดยเฉพาะอย่างยิ

่ง
่องจักรหรือระบบคอมพิวเตอร์มีความชาญฉลาด 
้ 
้และตัดสินใจ โดยใช้เหตุผลได้เสมือนสมองของมนุษย์ และสามารถเรียนรู

่มศักยภาพของปัญญาประดิษฐ์เองได้ 

่อเพิ

้วิจัยปัญญาประดิษฐ์ หมายถึง ผู
้ปัญญาประดิษฐ์ที

่มีอยู

ผู
องค์ความรู
ยอมรับจากทุกศาสตร์ที

่เกี

่ยวข้องว่ามีความน่าเชื

่อถือ  

้ค้นคว้าหาองค์ความรู

้ปัญญาประดิษฐ์ใหม่ ๆ หรือเพื

่ โดยมีกระบวนการคิดอย่างเป็นระบบและใช้วิธีการหรือเทคนิคที

่อประยุกต์ใช้
่ได้รับการ

ผู

้ออกแบบปัญญาประดิษฐ์ หมายถึง ผู
ปัญญาประดิษฐ์มาจัดท าแบบแผนในการสร้างปัญญาประดิษฐ์ เพื
ต้องการของผู

้ใช้งานปัญญาประดิษฐ์ 

้มีหน้าที

่ศึกษาและวิเคราะห์ความต้องการของผู

้ใช้งาน
่อให้สามารถใช้งานได้จริงและตรงตามความ

ผู

้พัฒนาปัญญาประดิษฐ์ หมายถึง ผู

้มีหน้าที

่พัฒนาปัญญาประดิษฐ์ตามแบบแผนที

้ออกแบบ
่อตรวจสอบว่าปัญญาประดิษฐ์

่ผู

ปัญญาประดิษฐ์ออกแบบไว้ และท าการทดสอบใช้งานปัญญาประดิษฐ์เพื
สามารถใช้งานได้จริงและตรงความต้องการ 

ผู

้ใช้งานปัญญาประดิษฐ์ หมายถึง กลุ

่ระบุ
่ต้องการให้ปัญญาประดิษฐ์ให้ความช่วยเหลือและแก้ไขปัญหาให้โดยหมายความ

้รับบริการปัญญาประดิษฐ์ โดยมีหน้าที

่มบุคคลผู

้เป็นผู

ปัญหาและความต้องการที
รวมถึงประชาชนทุกคนและกลุ

่มคนส่วนน้อย เช่น ผู

้ด้อยโอกาส ผู

้พิการ และผู

้ทุพพลภาพ 

หน่วยงานควบคุมดูแลการพัฒนาและใช้งานปัญญาประดิษฐ์ หมายถึง หน่วยงานภาครัฐ 
่ยวข้องกับการวิจัย ออกแบบ พัฒนา และใช้งาน
ผู
่ควบคุม ก ากับ ดูแล บุคคลและหน่วยงานที
้มีหน้าที
ปัญญาประดิษฐ์ ให้สอดคล้องกับจริยธรรมปัญญาประดิษฐ์ในทุกขั
้นตอนการท างาน โดยมีการก าหนดอ านาจ 
หน้าที

่ความรับผิดชอบ และบทลงโทษไว้อย่างชัดเจน 

่เกี

ความโปร่งใส (Transparency) หมายถึง การที
้นย้อนหลังได้ทั

่สามารถอธิบายเหตุการณ์ การกระท า 
กระบวนการท างาน และกิจกรรมต่าง ๆ ที
่อให้หน่วยงานควบคุมดูแลการ
้งหมด เพื
พัฒนาและใช้งานปัญญาประดิษฐ์สามารถตรวจสอบกิจกรรมต่าง ๆ ว่าด าเนินไปด้วยความถูกต้อง  และ
สามารถคาดการณ์การกระท าต่าง ๆ ได้ 

่เกิดขึ

36 | P a g e  

 
 
Digital Thailand - AI Ethics Guideline 

ภาระความรับผิดชอบ (Accountability) หมายถึง ภาระความรับผิดชอบที

่เกิดขึ

้ที
้นจากปัญญาประดิษฐ์ โดยให้ผู
้ใช้งานปัญญาประดิษฐ์ รับผิดชอบเยียวยาผู

่ยวข้องกับปัญญาประดิษฐ์ เช่น ผู

่เกี
้ได้รับผลกระทบเฉพาะที

้ออกแบบ ผู
้วิจัย ผู
่เกิดจากขอบเขตภาระหน้าที

่มี หากเกิด 
้พัฒนา
่เฉพาะ

ผลกระทบที
และผู
ส่วนของตนเท่านั

้น 

ความสามารถในการสืบย้อน (Traceability) หมายถึง ความสามารถในการตรวจสอบ
่อใช้ใน

่มาของชุดข้อมูล กระบวนการท างานและการตัดสินใจของปัญญาประดิษฐ์ เพื

่พบ และสามารถวินิจฉัยปัญหาที

่ท าให้เกิดความผิดพลาดล้มเหลวได้ 

ย้อนกลับไปตั
้งแต่แหล่งที
การเฝ้าระวัง ตรวจสอบความผิดปกติที

ความมั

่นคงปลอดภัย (Security) หมายถึง การสร้างความมั

โดยอาจใช้นโยบายและมาตรฐานทางเทคนิคด้านความมั
ความเสี
เพื
ด้านจริยธรรม ชีวิตและสิ

่นคงปลอดภัยให้แก่ปัญญาประดิษฐ์ 
่นคงปลอดภัย การเฝ้าระวัง การประเมินและจัดการ
้มครองความเป็นส่วนตัว ส าหรับการวิจัย ออกแบบ พัฒนาและใช้งานปัญญาประดิษฐ์ 
่ก่อให้เกิดผลกระทบในด้านลบ รวมถึงผลกระทบ
้ให้บริการปฏิบัติตาม 

่อลดช่องโหว่และป้องกันภัยคุกคามของปัญญาประดิษฐ์ที

่งแวดล้อม และให้ผู

้พัฒนา และผู

้ออกแบบ ผู

่ยง การคุ

้วิจัย ผู

ความเป็นส่วนตัว (Privacy) หมายถึง ข้อมูลส่วนบุคคลที

ซึ
่งหากต้องการน าข้อมูลส่วนบุคคลของผู
บุคคล โดยต้องท าการแจ้งให้ผู
การน าไปใช้ และข้อมูลส่วนบุคคลดังกล่าวต้องได้รับการยินยอมจากเจ้าของข้อมูลเสียก่อน 

้ใช้งานปัญญาประดิษฐ์ทราบเป็นการล่วงหน้าถึงข้อมูลที

้ใดไปใช้งาน จะต้องไม่ด าเนินการขัดกับกฎหมายคุ

่เป็นสิทธิเสรีภาพส่วนบุคคลของมนุษย์ 
้มครองข้อมูลส่วน
่จะถูกเก็บรวบรวมและ

ความเป็นธรรม (Fairness) หมายถึง ความเท่าเทียมกันทางด้านโอกาสในสังคม โดยผู
่มคนด้อยโอกาส เช่น  ผู

ประโยชน์จากปัญญาประดิษฐ์ ควรเป็นประชาชนทุกคน รวมถึงกลุ
้ทุพพลภาพด้วย 
ผู

้ที
่จะได้รับ
้พิการและ 

่อถือ (Reliability) หมายถึง คุณภาพของปัญญาประดิษฐ์ในด้านต่าง ๆ ที

่ส่งผลให้เกิด
้ใช้งานปัญญาประดิษฐ์ เช่น ความถูกต้องแม่นย า ความสมบูรณ์ ความเป็นปัจจุบัน  

ความน่าเชื
่อถือต่อผู
่ยวข้องของข้อมูล ความครบถ้วนถูกต้อง การคาดการณ์ได้ถูกต้องแม่นย า และความสามารถในการ

ความเชื
ความเกี
น าไปใช้  

37 | P a g e  

 
 
 
Digital Thailand - AI Ethics Guideline 

เอกสำรอ้ำงอิง (Reference) 

1.  OECD Legal Instruments. Recommendation of the Council on Artificial Intelligence. 
May 22 2019. จาก https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-
0449.  

2.  Beijing AI Principles. May 5 2019. จาก https://www.baai.ac.cn/blog/beijing-ai-principles.  
3.  European Commission. Ethics Guidelines for Trustworthy AI. Apr 8 2019. จาก 

https://ec.europa.eu/digital-single-market/en/news/ethics-guidelines-trustworthy-ai. 
4.  UNESCO and EQUALS Skills Coalition. I’d blush if I could: Closing gender divides in 

digital skills through education. 2019. จาก 
https://unesdoc.unesco.org/ark:/48223/pf0000367416. 

5.  The White House. Executive Order on Maintaining American Leadership in AI. Feb 11 

2019. จาก https://www.whitehouse.gov/presidential-actions/executive-order-
maintaining-american-leadership-artificial-intelligence/. 

6.  Microsoft. The Future Computed, Artificial Intelligence and its role in society. Feb 
2019. จาก https://3er1viui9wo30pkxh1v2nh4w-wpengine.netdna-ssl.com/wp-
content/uploads/2018/02/The-Future-Computed_2.8.18.pdf. 

7.  Microsoft. Six principles to guide Microsoft’s facial recognition work. Dec 2018. จาก 
https://blogs.microsoft.com/on-the-issues/2018/12/17/six-principles-to-guide-
microsofts-facial-recognition-work/. 

8.  Microsoft. Responsible bots: 10 guidelines for developers of conversational AI. Nov 

2018. จาก https://www.microsoft.com/en-
us/research/uploads/prod/2018/11/Bot_Guidelines_Nov_2018.pdf. 
9.  Smart Dubai. AI Ethics Principles & Guidelines. Version 1.6. Dec 30 2018. 
10. Council of Europe. Guidelines on Artificial Intelligence and Data Protection. 

Consultative Committee of the Convention for the Protection of individuals with 
regard to Automatic Processing of Personal Data. Jan 25 2019. 

11. Personal Data Protection Commission, Singapore. A Proposed Model Artificial 

Intelligence Governance Framework. Jan 2019. 

38 | P a g e  

 
 
Digital Thailand - AI Ethics Guideline 

12. David Silver at all. Mastering the game of Go with Deep neural networks and tree 

search. Nature. Jan 2016. จาก
https://storage.googleapis.com/deepmindmedia/alphago/AlphaGoNaturePaper.pdf. 

13. Monegain B. IBM Watson pinpoints rare form of leukemia after doctor misdiagnosed 

patient. Healthcare IT News. Aug 8  2016. จาก 
https://www.healthcareitnews.com/news/ibm-watson-pinpoints-rare-form-leukemia-
after-doctors-misdiagnosed-patient. 

14. Julia Angwin., Jeff Larson., Surya Mattu. and Lauren Kirchner. Machine Bias: There’s 
software used across the country to predict future criminals. And it’s biased against 
blacks. ProPublica. May 23 2016. จาก https://www.propublica.org/article/machine-
bias-risk-assessments-in-criminal-sentencing.  

15. Dhilung Kirat., Juyong Jang., and Marc Ph. Stoecklin. DeepLocker – Concealing 
Targeted Attacks with AI Locksmithing. Blackhat USA 2018. Aug 9 2018. จาก 
https://www.blackhat.com/us-18/briefings/schedule/#deeplocker---concealing-
targeted-attacks-with-ai-locksmithing-11549. 

16. ประกาศ เรื

่อง ยุทธศาสตร์ชาติ (พ.ศ. 2561 – 2580). ราชกิจจานุเบกษา. 13 ตุลาคม พ.ศ. 2561 

่ 82 ก. หน้า 25. จาก 

เล่ม 135 ตอนที
http://www.ratchakitcha.soc.go.th/DATA/PDF/2561/A/082/T_0001.PDF.  
่อเศรษฐกิจและสังคม พ.ศ. 2563 – 2567. หน้า 5. 

17. แผนยุทธศาสตร์กระทรวงดิจิทัลเพื

http://www.mdes.go.th/assets/portals/1/files/%E0%B9%81%E0%B8%9C%E0%B8%99%E
0%B8%A2%E0%B8%B8%E0%B8%97%E0%B8%98%E0%B8%A8%E0%B8%B2%E0%B8%A
A%E0%B8%95%E0%B8%A3%E0%B9%8C%20%E0%B8%94%E0%B8%A8.%2063-
67%20final%281%29.pdf. 

18. David Gilbert. Russian weapons maker Kalashnikov developing killer AI robots. Vice 

News. Jul 13 2017. จาก https://news.vice.com/en_us/article/vbzq8y/russian-weapons-
maker-kalashnikov-developing-killer-ai-robots. 

19. Marcus Roth. AI in Military Drones and UAVs – Current Applications. Emerj. Jan 30 
2019. จาก https://emerj.com/ai-sector-overviews/ai-drones-and-uavs-in-the-military-
current-applications/. 

39 | P a g e  

 
Digital Thailand - AI Ethics Guideline 

20. Kate Conger. Google Employees Resign in Protest Against Pentagon Contract. 
GIZMODO. May 14 2018. จาก https://gizmodo.com/google-employees-resign-in-
protest-against-pentagon-con-1825729300. 

21. Osterman Research White Paper. The State of AI in Cybersecurity: The Benefits, 

Limitations and Evolving Questions. Dec 2018. 

22. Abigail Abrams. Data Breach at Sears and Delta May Have Hit ‘Several Hundred 

Thousand’ Customers. TIME USA, LLC. Apr 6 2018. จาก 
https://time.com/5230288/delta-sears-data-breach-credit-cards/. 

23. Sarah Perez. Microsoft silences its new A.I. bot Tay, after Twitter users teach it racism. 
Verizon Media. Mar 24 2016. จาก https://techcrunch.com/2016/03/24/microsoft-
silences-its-new-a-i-bot-tay-after-twitter-users-teach-it-racism/. 

24. Sarah Myers West., Meredith Whittaker., and Kate Crawford. Discrimination Systems: 

Gender, Race, and Power in AI. AINOW Institute. Apr 2019. จาก 
https://ainowinstitute.org/discriminatingsystems.pdf. 

25. Natasha Singer. Amazon Is Pushing Facial Technology That a Study Says Cloud Be 

Biased. The New York Times. Jan 24 2019. จาก 
https://www.nytimes.com/2019/01/24/technology/amazon-facial-technology-
study.html. 

26. Sophie Curtis. Google Photos labels black people as ‘gorillas’. The Telegraph. Jul 01 
2015. จาก https://www.telegraph.co.uk/technology/google/11710136/Google-Photos-
assigns-gorilla-tag-to-photos-of-black-people.html. 

27. Jacob Snow. Amazon’s Face Recognition Falsely Matched 28 Members of Congress 

With Mugshots. American Civil Liberties Union. Jul 26 2018. จาก 
https://www.aclu.org/blog/privacy-technology/surveillance-technologies/amazons-
face-recognition-falsely-matched-28. 

40 | P a g e  

 
 
 
Digital Thailand - AI Ethics Guideline 

41 | P a g e  

 
 
